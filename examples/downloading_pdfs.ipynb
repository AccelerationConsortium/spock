{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv \n",
    "import requests\n",
    "import os \n",
    "import re \n",
    "import urllib.request\n",
    "import json\n",
    "import re\n",
    "import requests \n",
    "import os \n",
    "\n",
    "\n",
    "\n",
    "def standard_url_alphanumeric(input_string):\n",
    "    allowed_characters = r'[a-zA-Z0-9\\-._~:/?#\\[\\]@!$&\\'()*+,;=%]'\n",
    "    cleaned_string = re.sub(r'[^\\w\\s-]', ' ', input_string) \n",
    "    cleaned_string = re.sub(r'[-\\s]+', '-', cleaned_string)\n",
    "    cleaned_string = cleaned_string.strip(\"-\")\n",
    "    cleaned_string = \"\".join(re.findall(allowed_characters, cleaned_string))\n",
    "    cleaned_string = cleaned_string.lower()\n",
    "    return cleaned_string\n",
    "\n",
    "def standard_url_alphanumeric_arxiv(input_string):\n",
    "    return standard_url_alphanumeric(input_string).strip('-')\n",
    "\n",
    "def standard_title_alphanumeric_chemarxiv(input_string):\n",
    "    return standard_url_alphanumeric(input_string).strip('_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Publication:\n",
    "    def __init__(self,publication_filled, llm_use:bool=True) -> None:\n",
    "        self.publication_filled = publication_filled\n",
    "        self.title = self.get_publication_title()\n",
    "        self.pdf = self.get_pdf()\n",
    "\n",
    "    def get_publication_title(self) -> str:\n",
    "        try:\n",
    "            return self.publication_filled['bib']['title']\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def arxiv_downloader(self, directory):\n",
    "        search = arxiv.Search(\n",
    "            query = self.title, \n",
    "            max_results = 1, \n",
    "            sort_by = arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        client = arxiv.Client()\n",
    "        results = client.results(search)\n",
    "        for result in results:\n",
    "            if result.title.lower() == self.title.lower():\n",
    "                print(\"Article found.\")\n",
    "                url = result.pdf_url \n",
    "                self.pdf = url # Maybe to Split the function in 2\n",
    "                \n",
    "                \n",
    "                \n",
    "                response = requests.get(url)\n",
    "                os.makedirs(directory, exist_ok = True)\n",
    "                title = standard_url_alphanumeric_arxiv(self.title)\n",
    "                with open(f\"{title}.pdf\", \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def search_chemrxiv_by_title(self, max_results: int = 1):\n",
    "        search_query = self.title.split()\n",
    "        chemrxiv_url = f'https://chemrxiv.org/engage/chemrxiv/public-api/v1/items?term={\"%20\".join(search_query)}&sort=RELEVANT_DESC&limit={max_results}'\n",
    "\n",
    "        try:\n",
    "            req = urllib.request.Request(\n",
    "                url=chemrxiv_url, \n",
    "                headers={'User-Agent': 'Mozilla/5.0'}\n",
    "            )\n",
    "            with urllib.request.urlopen(req) as response:\n",
    "                s = response.read()\n",
    "                jsonResponse = json.loads(s.decode('utf-8'))\n",
    "                dois = [item[\"item\"][\"doi\"] for item in jsonResponse[\"itemHits\"]]\n",
    "                urls = [\"https://doi.org/\" + doi for doi in dois]\n",
    "                ids = [item[\"item\"][\"id\"] for item in jsonResponse[\"itemHits\"]]\n",
    "                titles = [item[\"item\"][\"title\"].replace(\"\\n\", \"\") for item in jsonResponse[\"itemHits\"]]\n",
    "                titles = [standard_url_alphanumeric(self.title) for title in titles]\n",
    "                pdfs = [\"https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/\" + id + \"/original/\" for id in ids]\n",
    "                pdfs = [pdf + title + \".pdf\" for pdf, title in zip(pdfs, titles)]\n",
    "                return titles, pdfs\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred.\"\n",
    "\n",
    "    def pdf_downloader(self, pdf_link, directory):\n",
    "        os.makedirs(directory, exist_ok = True)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(pdf_link)\n",
    "            response.raise_for_status()\n",
    "            title = standard_title_alphanumeric_chemarxiv(self.title)\n",
    "            with open(f\"{title}.pdf\", \"wb\") as pdf_file:\n",
    "                pdf_file.write(response.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to donwload {pdf_link}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spock_package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
