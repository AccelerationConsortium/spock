{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bfa978e",
   "metadata": {},
   "source": [
    "## The LLM bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5994758-ba58-4c48-919e-bf63e0803e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: module: command not found\n",
      "Package                                  Version         Editable project location\n",
      "---------------------------------------- --------------- -------------------------\n",
      "aiohttp                                  3.9.5\n",
      "aiosignal                                1.3.1\n",
      "alabaster                                0.7.16\n",
      "annotated-types                          0.7.0\n",
      "anyio                                    4.4.0\n",
      "argon2-cffi                              23.1.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "arrow                                    1.3.0\n",
      "arxiv                                    2.1.3\n",
      "asgiref                                  3.8.1\n",
      "asttokens                                2.4.1\n",
      "async-lru                                2.0.4\n",
      "attrs                                    23.2.0\n",
      "Babel                                    2.15.0\n",
      "backoff                                  2.2.1\n",
      "backports.tarfile                        1.2.0\n",
      "bcrypt                                   4.1.3\n",
      "beautifulsoup4                           4.12.3\n",
      "bibtexparser                             1.4.1\n",
      "binaryornot                              0.4.4\n",
      "bleach                                   6.1.0\n",
      "bracex                                   2.4\n",
      "build                                    1.2.1\n",
      "bump-my-version                          0.22.0\n",
      "cachetools                               5.3.3\n",
      "certifi                                  2024.6.2\n",
      "cffi                                     1.16.0\n",
      "chardet                                  5.2.0\n",
      "charset-normalizer                       3.3.2\n",
      "chroma-hnswlib                           0.7.3\n",
      "chromadb                                 0.5.0\n",
      "click                                    8.1.7\n",
      "coloredlogs                              15.0.1\n",
      "comm                                     0.2.2\n",
      "cookiecutter                             2.6.0\n",
      "cryptography                             42.0.8\n",
      "dataclasses-json                         0.6.7\n",
      "debugpy                                  1.8.1\n",
      "decorator                                5.1.1\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.14\n",
      "distro                                   1.9.0\n",
      "dnspython                                2.6.1\n",
      "docutils                                 0.20.1\n",
      "email_validator                          2.1.2\n",
      "execnet                                  2.1.1\n",
      "executing                                2.0.1\n",
      "fake-useragent                           1.5.1\n",
      "fastapi                                  0.111.0\n",
      "fastapi-cli                              0.0.4\n",
      "fastembed                                0.3.1\n",
      "fastjsonschema                           2.19.1\n",
      "feedparser                               6.0.11\n",
      "filelock                                 3.15.1\n",
      "flatbuffers                              24.3.25\n",
      "fqdn                                     1.5.1\n",
      "free-proxy                               1.1.1\n",
      "frozenlist                               1.4.1\n",
      "fsspec                                   2024.6.0\n",
      "google-auth                              2.30.0\n",
      "googleapis-common-protos                 1.63.1\n",
      "greenlet                                 3.0.3\n",
      "grpcio                                   1.64.1\n",
      "h11                                      0.14.0\n",
      "httpcore                                 1.0.5\n",
      "httptools                                0.6.1\n",
      "httpx                                    0.27.0\n",
      "huggingface-hub                          0.23.4\n",
      "humanfriendly                            10.0\n",
      "idna                                     3.7\n",
      "imagesize                                1.4.1\n",
      "importlib_metadata                       7.1.0\n",
      "importlib_resources                      6.4.0\n",
      "iniconfig                                2.0.0\n",
      "ipykernel                                6.29.4\n",
      "ipython                                  8.25.0\n",
      "ipywidgets                               8.1.3\n",
      "isoduration                              20.11.0\n",
      "jaraco.classes                           3.4.0\n",
      "jaraco.context                           5.3.0\n",
      "jaraco.functools                         4.0.1\n",
      "jedi                                     0.19.1\n",
      "jeepney                                  0.8.0\n",
      "Jinja2                                   3.1.4\n",
      "json5                                    0.9.25\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              3.0.0\n",
      "jsonschema                               4.22.0\n",
      "jsonschema-specifications                2023.12.1\n",
      "jupyter                                  1.0.0\n",
      "jupyter_client                           8.6.2\n",
      "jupyter-console                          6.6.3\n",
      "jupyter_core                             5.7.2\n",
      "jupyter-events                           0.10.0\n",
      "jupyter-lsp                              2.2.5\n",
      "jupyter_server                           2.14.1\n",
      "jupyter_server_terminals                 0.5.3\n",
      "jupyterlab                               4.2.2\n",
      "jupyterlab_pygments                      0.3.0\n",
      "jupyterlab_server                        2.27.2\n",
      "jupyterlab_widgets                       3.0.11\n",
      "keyring                                  25.2.1\n",
      "kubernetes                               30.1.0\n",
      "langchain                                0.2.3\n",
      "langchain-community                      0.2.4\n",
      "langchain-core                           0.2.21\n",
      "langchain-openai                         0.1.17\n",
      "langchain-text-splitters                 0.2.1\n",
      "langchainhub                             0.1.20\n",
      "langsmith                                0.1.77\n",
      "loguru                                   0.7.2\n",
      "lxml                                     5.2.2\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.1.5\n",
      "marshmallow                              3.21.3\n",
      "matplotlib-inline                        0.1.7\n",
      "mdurl                                    0.1.2\n",
      "mistune                                  3.0.2\n",
      "mmh3                                     4.1.0\n",
      "monotonic                                1.6\n",
      "more-itertools                           10.3.0\n",
      "mpmath                                   1.3.0\n",
      "multidict                                6.0.5\n",
      "mypy-extensions                          1.0.0\n",
      "nbclient                                 0.10.0\n",
      "nbconvert                                7.16.4\n",
      "nbformat                                 5.10.4\n",
      "nest-asyncio                             1.6.0\n",
      "nh3                                      0.2.17\n",
      "notebook                                 7.2.1\n",
      "notebook_shim                            0.2.4\n",
      "numpy                                    1.26.4\n",
      "oauthlib                                 3.2.2\n",
      "ollama                                   0.2.1\n",
      "onnx                                     1.16.1\n",
      "onnxruntime                              1.18.0\n",
      "openai                                   1.35.15\n",
      "opentelemetry-api                        1.25.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.25.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.25.0\n",
      "opentelemetry-instrumentation            0.46b0\n",
      "opentelemetry-instrumentation-asgi       0.46b0\n",
      "opentelemetry-instrumentation-fastapi    0.46b0\n",
      "opentelemetry-proto                      1.25.0\n",
      "opentelemetry-sdk                        1.25.0\n",
      "opentelemetry-semantic-conventions       0.46b0\n",
      "opentelemetry-util-http                  0.46b0\n",
      "orjson                                   3.10.4\n",
      "outcome                                  1.3.0.post0\n",
      "overrides                                7.7.0\n",
      "packaging                                23.2\n",
      "pandocfilters                            1.5.1\n",
      "parso                                    0.8.4\n",
      "pdfminer.six                             20231228\n",
      "pdfplumber                               0.11.1\n",
      "pexpect                                  4.9.0\n",
      "pillow                                   10.3.0\n",
      "pip                                      24.0\n",
      "pkginfo                                  1.11.1\n",
      "platformdirs                             4.2.2\n",
      "pluggy                                   1.5.0\n",
      "posthog                                  3.5.0\n",
      "prometheus_client                        0.20.0\n",
      "prompt_toolkit                           3.0.47\n",
      "protobuf                                 4.25.3\n",
      "psutil                                   5.9.8\n",
      "ptyprocess                               0.7.0\n",
      "pure-eval                                0.2.2\n",
      "pyasn1                                   0.6.0\n",
      "pyasn1_modules                           0.4.0\n",
      "pycparser                                2.22\n",
      "pydantic                                 2.7.4\n",
      "pydantic_core                            2.18.4\n",
      "pydantic-settings                        2.3.2\n",
      "Pygments                                 2.18.0\n",
      "pyparsing                                3.1.2\n",
      "pypdfium2                                4.30.0\n",
      "PyPika                                   0.48.9\n",
      "pyproject_hooks                          1.1.0\n",
      "PySocks                                  1.7.1\n",
      "PyStemmer                                2.2.0.1\n",
      "pytest                                   8.2.2\n",
      "pytest-xdist                             3.6.1\n",
      "python-dateutil                          2.9.0.post0\n",
      "python-dotenv                            1.0.1\n",
      "python-json-logger                       2.0.7\n",
      "python-multipart                         0.0.9\n",
      "python-slugify                           8.0.4\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    26.0.3\n",
      "qtconsole                                5.5.2\n",
      "QtPy                                     2.4.1\n",
      "questionary                              2.0.1\n",
      "readme_renderer                          43.0\n",
      "referencing                              0.35.1\n",
      "regex                                    2024.5.15\n",
      "requests                                 2.32.3\n",
      "requests-oauthlib                        2.0.0\n",
      "requests-toolbelt                        1.0.0\n",
      "rfc3339-validator                        0.1.4\n",
      "rfc3986                                  2.0.0\n",
      "rfc3986-validator                        0.1.1\n",
      "rich                                     13.7.1\n",
      "rich-click                               1.8.3\n",
      "rpds-py                                  0.18.1\n",
      "rsa                                      4.9\n",
      "scholarly                                1.7.11\n",
      "scidownl                                 1.0.2\n",
      "SecretStorage                            3.3.3\n",
      "selenium                                 4.21.0\n",
      "Send2Trash                               1.8.3\n",
      "setuptools                               69.5.1\n",
      "sgmllib3k                                1.0.0\n",
      "shellingham                              1.5.4\n",
      "six                                      1.16.0\n",
      "slack_bolt                               1.19.0\n",
      "slack_sdk                                3.29.0\n",
      "sniffio                                  1.3.1\n",
      "snowballstemmer                          2.2.0\n",
      "sortedcontainers                         2.4.0\n",
      "soupsieve                                2.5\n",
      "Sphinx                                   7.3.7\n",
      "sphinx-rtd-theme                         2.0.0\n",
      "sphinxcontrib-applehelp                  1.0.8\n",
      "sphinxcontrib-devhelp                    1.0.6\n",
      "sphinxcontrib-htmlhelp                   2.0.5\n",
      "sphinxcontrib-jquery                     4.1\n",
      "sphinxcontrib-jsmath                     1.0.1\n",
      "sphinxcontrib-qthelp                     1.0.7\n",
      "sphinxcontrib-serializinghtml            1.1.10\n",
      "spock-literature                         0.0.7           /home/youssef/clone/spock\n",
      "SQLAlchemy                               2.0.30\n",
      "stack-data                               0.6.3\n",
      "starlette                                0.37.2\n",
      "sympy                                    1.12.1\n",
      "tablib                                   3.6.1\n",
      "tabulate                                 0.9.0\n",
      "tenacity                                 8.3.0\n",
      "terminado                                0.18.1\n",
      "text-unidecode                           1.3\n",
      "tiktoken                                 0.7.0\n",
      "tinycss2                                 1.3.0\n",
      "tokenizers                               0.19.1\n",
      "tomlkit                                  0.12.5\n",
      "tornado                                  6.4.1\n",
      "tqdm                                     4.66.4\n",
      "traitlets                                5.14.3\n",
      "trio                                     0.25.1\n",
      "trio-websocket                           0.11.1\n",
      "twine                                    5.1.0\n",
      "typer                                    0.12.3\n",
      "types-python-dateutil                    2.9.0.20240316\n",
      "types-requests                           2.32.0.20240712\n",
      "typing_extensions                        4.12.2\n",
      "typing-inspect                           0.9.0\n",
      "ujson                                    5.10.0\n",
      "uri-template                             1.3.0\n",
      "urllib3                                  2.2.1\n",
      "uvicorn                                  0.30.1\n",
      "uvloop                                   0.19.0\n",
      "watchfiles                               0.22.0\n",
      "wcmatch                                  8.5.2\n",
      "wcwidth                                  0.2.13\n",
      "webcolors                                24.6.0\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.8.0\n",
      "websockets                               12.0\n",
      "wget                                     3.2\n",
      "wheel                                    0.43.0\n",
      "widgetsnbextension                       4.0.11\n",
      "wrapt                                    1.16.0\n",
      "wsproto                                  1.2.0\n",
      "yarl                                     1.9.4\n",
      "zipp                                     3.19.2\n",
      "Requirement already satisfied: langchain in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (0.2.3)\n",
      "Requirement already satisfied: langchain_community in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain_core in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (0.2.21)\n",
      "Requirement already satisfied: scholarly in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (1.7.11)\n",
      "Requirement already satisfied: pdfplumber in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (0.11.1)\n",
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: arrow in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (1.3.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (4.12.3)\n",
      "Requirement already satisfied: bibtexparser in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (1.4.1)\n",
      "Requirement already satisfied: deprecated in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (1.2.14)\n",
      "Requirement already satisfied: fake-useragent in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (1.5.1)\n",
      "Requirement already satisfied: free-proxy in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (1.1.1)\n",
      "Requirement already satisfied: httpx in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (0.27.0)\n",
      "Requirement already satisfied: python-dotenv in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (1.0.1)\n",
      "Requirement already satisfied: selenium in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (4.21.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from scholarly) (4.12.2)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pdfplumber) (10.3.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain_core\n",
      "  Downloading langchain_core-0.2.28-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from arrow->scholarly) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from arrow->scholarly) (2.9.0.20240316)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from beautifulsoup4->scholarly) (2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from bibtexparser->scholarly) (3.1.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from deprecated->scholarly) (1.16.0)\n",
      "Requirement already satisfied: lxml in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from free-proxy->scholarly) (5.2.2)\n",
      "Requirement already satisfied: anyio in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from httpx->scholarly) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from httpx->scholarly) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from httpx->scholarly) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from httpcore==1.*->httpx->scholarly) (0.14.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from requests[socks]->scholarly) (1.7.1)\n",
      "Requirement already satisfied: trio~=0.17 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from selenium->scholarly) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from selenium->scholarly) (0.11.1)\n",
      "Requirement already satisfied: sphinx<8,>=5 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx-rtd-theme->scholarly) (7.3.7)\n",
      "Requirement already satisfied: docutils<0.21 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx-rtd-theme->scholarly) (0.20.1)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx-rtd-theme->scholarly) (4.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.8)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.6)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.0.7)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (3.1.4)\n",
      "Requirement already satisfied: Pygments>=2.14 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.18.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.15.0)\n",
      "Requirement already satisfied: alabaster~=0.7.14 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from sphinx<8,>=5->sphinx-rtd-theme->scholarly) (1.4.1)\n",
      "Requirement already satisfied: sortedcontainers in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from trio~=0.17->selenium->scholarly) (2.4.0)\n",
      "Requirement already satisfied: outcome in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from trio~=0.17->selenium->scholarly) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium->scholarly) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/youssef/anaconda3/envs/spock_package/lib/python3.11/site-packages (from Jinja2>=3.0->sphinx<8,>=5->sphinx-rtd-theme->scholarly) (2.1.5)\n",
      "Downloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.28-py3-none-any.whl (379 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_core, langchain, langchain_community, langchain_experimental\n",
      "  Attempting uninstall: langchain_core\n",
      "    Found existing installation: langchain-core 0.2.21\n",
      "    Uninstalling langchain-core-0.2.21:\n",
      "      Successfully uninstalled langchain-core-0.2.21\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.3\n",
      "    Uninstalling langchain-0.2.3:\n",
      "      Successfully uninstalled langchain-0.2.3\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.2.4\n",
      "    Uninstalling langchain-community-0.2.4:\n",
      "      Successfully uninstalled langchain-community-0.2.4\n",
      "Successfully installed langchain-0.2.12 langchain_community-0.2.11 langchain_core-0.2.28 langchain_experimental-0.0.64\n"
     ]
    }
   ],
   "source": [
    "!module load python\n",
    "!pip list\n",
    "!pip install langchain langchain_community langchain_core scholarly pdfplumber langchain_experimental\n",
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader, TextLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "import json\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import requests\n",
    "from scholarly import scholarly\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc478dc-d890-4b55-ac5f-fbb144d2585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PDFPlumberLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "class Bot_LLM:\n",
    "    def __init__(self,model='llama3',embed_model='mxbai-embed-large', folder_path='db2'):\n",
    "        self.llm = Ollama(model=model)\n",
    "        self.oembed = OllamaEmbeddings(model=embed_model)\n",
    "        self.folder_path = folder_path\n",
    "        self.vectorestore = None\n",
    "\n",
    "    \n",
    "    def get_topic_publication_abstract(self, abstract:str, input_file:str):\n",
    "        with open(input_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        parser = JsonOutputParser()\n",
    "        \n",
    "        new_text = \"\"\"The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
    "\n",
    "        As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
    "        the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
    "\n",
    "        Here is the output schema:\n",
    "        ```\n",
    "        {\"topic\": {'Machine Learning: [Keyword1, keyword2, keyword3], 'Batteries: [keyword1, keyword2, keyword3]}\n",
    "        ```\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"Here is a text: {abstract} Please identify the topics from the following list: {liste}. Note: A single text can belong to multiple topics, so please list all relevant topics.  \\n{format_instructions}\"\n",
    "        ,\n",
    "            input_variables=[\"abstract\",\"liste\",\"topics\"],\n",
    "            partial_variables={\"format_instructions\": new_text}\n",
    "        )\n",
    "\n",
    "\n",
    "        chain = prompt | self.llm | parser\n",
    "        topics = chain.invoke({\"abstract\": abstract, \"liste\": data.keys()})\n",
    "        print('Topics: ', topics['topic'])\n",
    "        return topics['topic']\n",
    "\n",
    "    def decomposition(self, question):\n",
    "        from langchain.prompts import ChatPromptTemplate\n",
    "        from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "        # Decomposition\n",
    "        template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "        The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "        Generate multiple search queries related to: {question} \\n\n",
    "        Output (3 queries):\"\"\"\n",
    "        prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
    "        generate_queries_decomposition = ( prompt_decomposition | self.llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "        \n",
    "        questions = generate_queries_decomposition.invoke({\"question\":question})\n",
    "        print(questions)\n",
    "        # Prompt\n",
    "        template = \"\"\"Here is the question you need to answer:\n",
    "        \n",
    "        \\n --- \\n {question} \\n --- \\n\n",
    "        \n",
    "        Here is any available background question + answer pairs:\n",
    "        \n",
    "        \\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "        \n",
    "        Here is additional context relevant to the question: \n",
    "        \n",
    "        \\n --- \\n {context} \\n --- \\n\n",
    "        \n",
    "        Use the above context and any background question + answer pairs to answer the question: \\n {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        decomposition_prompt = ChatPromptTemplate.from_template(template)\n",
    "        from operator import itemgetter\n",
    "        \n",
    "        \n",
    "        def format_qa_pair(question, answer):\n",
    "            \"\"\"Format Q and A pair\"\"\"\n",
    "            \n",
    "            formatted_string = \"\"\n",
    "            formatted_string += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "            return formatted_string.strip()\n",
    "        \n",
    "        \n",
    "        q_a_pairs = \"\"\n",
    "        for q in questions:\n",
    "            \n",
    "            rag_chain = (\n",
    "            {\"context\": itemgetter(\"question\") | self.vectorstore.as_retriever(), \n",
    "             \"question\": itemgetter(\"question\"),\n",
    "             \"q_a_pairs\": itemgetter(\"q_a_pairs\")} \n",
    "            | decomposition_prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser())\n",
    "        \n",
    "            answer = rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "            q_a_pair = format_qa_pair(q,answer)\n",
    "            q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair\n",
    "            print(q_a_pairs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def chunk_indexing(self, document:str):\n",
    "        # Check if the document is a valid file path\n",
    "\n",
    "        data = []\n",
    "        if isinstance(document, str) and os.path.isfile(document):\n",
    "            try:\n",
    "                loader = PDFPlumberLoader(document)\n",
    "                data = loader.load()\n",
    "                chunk_size = 2000\n",
    "                chunk_overlap = 20\n",
    "\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Error loading PDF: {e}\")\n",
    "        else:\n",
    "            try:\n",
    "                # Treat the document as raw text content\n",
    "                if isinstance(document, str):\n",
    "                    data.append(Document(page_content=document))\n",
    "                elif isinstance(document, list):\n",
    "                    for text in document:\n",
    "                        data.append(Document(page_content=text))\n",
    "                chunk_size = 180\n",
    "                chunk_overlap = 5\n",
    "\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Error processing text: {e}\")\n",
    "\n",
    "            \n",
    "        text_splitter=text_splitter = SemanticChunker(\n",
    "    self.oembed, breakpoint_threshold_type=\"standard_deviation\")\n",
    "\n",
    "\n",
    "        all_splits = text_splitter.split_documents(data)\n",
    "        self.vectorstore = Chroma.from_documents(documents=all_splits, embedding=self.oembed, persist_directory=self.folder_path)\n",
    "        \n",
    "    def query_rag(self, question:str) -> None:\n",
    "        if self.vectorstore:\n",
    "            docs = self.vectorstore.similarity_search(question)\n",
    "            from langchain.chains import RetrievalQA\n",
    "            qachain=RetrievalQA.from_chain_type(self.llm, retriever=self.vectorstore.as_retriever(), verbose=True)\n",
    "            res = qachain.invoke({\"query\": question})\n",
    "            print(res['result'])\n",
    "            return res['result']\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"No documents loaded\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf8061-7979-48aa-8429-b6995127aceb",
   "metadata": {},
   "source": [
    "# The Publication Class: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d60eae0-6833-408f-a2e3-07964944b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class Publication:\n",
    "    def __init__(self,publication_filled, llm_use:bool=True) -> None:\n",
    "        self.publication_filled = publication_filled\n",
    "        self.title = self.get_publication_title()\n",
    "        self.abstract = self.get_publication_abstract().lower()\n",
    "        self.author = self.get_author_name()\n",
    "        self.year = self.get_year()\n",
    "        self.url = self.get_publication_url()\n",
    "        self.citation = self.get_citation()\n",
    "        self.pdf = None\n",
    "        self.topic = None\n",
    "    \n",
    "      \n",
    "      \n",
    "    '''  \n",
    "    def get_topic(self,output_file=\"json/ouput.json\", # à voir cette histoire avec get_topic et __get_topic\n",
    "                  input_file=\"json/response.json\") -> list[str]:\n",
    "        try:\n",
    "            with open(output_file,'r') as file:\n",
    "                data = json.load(file)\n",
    "            return data[self.author]['topic']\n",
    "        except Exception as e:\n",
    "            return self.__get_topic(input_file)\n",
    "     '''   \n",
    "    def get_publication_url(self) -> str:\n",
    "        return self.publication_filled['pub_url']\n",
    "    \n",
    "    def get_publication_title(self) -> str:\n",
    "        return self.publication_filled['bib']['title'] \n",
    "\n",
    "    def get_publication_abstract(self) -> str:\n",
    "        return self.publication_filled['bib']['abstract']\n",
    "\n",
    "    def get_author_name(self) -> str:\n",
    "        return self.publication_filled['bib']['author']\n",
    "\n",
    "    def get_year(self) -> str:\n",
    "        return self.publication_filled['bib']['pub_year']\n",
    "    \n",
    "    def get_citation(self) -> str:\n",
    "        return self.publication_filled['bib']['citation']\n",
    "    \n",
    "    def get_topic(self,llm,input_file=\"json/response.json\") -> None:\n",
    "        self.topic: dict = llm.get_topic_publication_abstract(abstract=self.abstract,input_file=input_file)\n",
    "        return self.topic\n",
    "    \n",
    "    def get_pdf(self):\n",
    "        query = self.title.replace(\" \", \"+\")\n",
    "        url = f\"https://scholar.google.com/scholar?q={query}\"\n",
    "        print(url)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            html_content = response.text\n",
    "            try:\n",
    "                self.pdf = self.__parse_google_scholar(html_content)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while fetching the PDF link: {e}\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "            return None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        self.available_attributes = {'title': self.title if self.title is not None else 'N/A',\n",
    "                                     'abstract' : self.abstract if self.abstract is not None else 'N/A',\n",
    "                                        'author': self.author if self.author is not None else 'N/A',\n",
    "                                        'year': self.year if self.year is not None else 'N/A',\n",
    "                                        'url': self.url if self.url is not None else 'N/A',\n",
    "                                        'citation': self.citation if self.citation is not None else 'N/A',\n",
    "                                        'pdf': self.pdf if self.pdf is not None else 'N/A',\n",
    "                                        'topic': self.topic if self.topic is not None else 'N/A'}\n",
    "        return str(self.available_attributes)\n",
    "\n",
    "\n",
    "        \n",
    "    def __parse_google_scholar(self,html_content):\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        a_tags = soup.find_all('a')\n",
    "        try:\n",
    "            pdf_link = [a['href'] for a in a_tags if 'href' in a.attrs and '.pdf' in a['href']][0]\n",
    "            print(f\"PDF link found: {pdf_link}\")\n",
    "            return pdf_link\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while parsing the PDF link: {e}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    def download_pdf(self,path):\n",
    "        \n",
    "        # Verifier si le path exist sinon le creer\n",
    "        \n",
    "        import os\n",
    "        import requests\n",
    "        \n",
    "        \n",
    "        path = path + self.title + \".pdf\"\n",
    "        if self.pdf is not None:\n",
    "            try:\n",
    "                response = requests.get(self.pdf)\n",
    "                if response.status_code == 200:\n",
    "                    with open(path, 'wb') as file:\n",
    "                        file.write(response.content)\n",
    "                    print(f\"PDF successfully downloaded and saved to {path}\")\n",
    "                else:\n",
    "                    print(f\"Failed to download the PDF. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred while downloading the PDF: {e}\")\n",
    "        else:\n",
    "            from scidownl import scihub_download\n",
    "            #  scidownl by title\n",
    "            try:\n",
    "                scihub_download(self.title, paper_type=\"title\", out=path)\n",
    "            except:\n",
    "                try:\n",
    "                    # By URL\n",
    "                    scihub_download(self.pdf, out=path)\n",
    "                except:\n",
    "                    print(\"Couldn't download the PDF\")\n",
    "           \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "     \n",
    "                    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42468463-5008-440a-a710-bd4a73d66915",
   "metadata": {},
   "source": [
    "# The Author\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48476c3c-3a8c-4503-bbf3-68347e88a9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nauthor = Author('Mehrad Ansari')\\npub = Publication(author.get_last_publication())\\n\\npub.download_pdf('pdfs/')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Author:\n",
    "    def __init__(self, author):\n",
    "        \"\"\"\n",
    "        Initialize an Author object.\n",
    "\n",
    "        Args:\n",
    "            author (str): The name of the author.\n",
    "        \"\"\"\n",
    "        self.author_name = author\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Return a string representation of the Author object.\n",
    "\n",
    "        Returns:\n",
    "            str: The name of the author.\n",
    "        \"\"\"\n",
    "        return self.author_name\n",
    "\n",
    "    def get_last_publication(self):\n",
    "        \"\"\"\n",
    "        Get the last publication of the author.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dict containing information about the last publication.\n",
    "        \"\"\"\n",
    "        search_query = scholarly.search_author(self.author_name)\n",
    "        first_author_result = next(search_query)\n",
    "        author = scholarly.fill(first_author_result)\n",
    "        first_publication = sorted(author['publications'], \n",
    "                                   key=lambda x: int(x['bib']['pub_year'])\n",
    "                                   if 'pub_year' in x['bib'] else 0, \n",
    "                                   reverse=True)[0]\n",
    "        first_publication_filled = scholarly.fill(first_publication)\n",
    "        return first_publication_filled\n",
    "\n",
    "    def setup_author(self, output_file, llm):\n",
    "        \"\"\"\n",
    "        Setup the author by adding their last publication to a JSON file.\n",
    "\n",
    "        Args:\n",
    "            output_file (str): The path to the JSON file.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        with open(output_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        author_last_publication = Publication(self.get_last_publication())\n",
    "        \n",
    "\n",
    "        \n",
    "        data[self.author_name] = {\n",
    "            \"title\": author_last_publication.title,\n",
    "            \"abstract\": author_last_publication.abstract,\n",
    "            \"topic\": author_last_publication.get_topic(llm=llm), \n",
    "            \"author\": author_last_publication.author, \n",
    "            \"year\": author_last_publication.year,\n",
    "            \"url\": author_last_publication.url,\n",
    "            \"pdf\": author_last_publication.pdf,\n",
    "        }\n",
    "        \n",
    "        \n",
    "        with open(output_file, 'w') as file:\n",
    "            json.dump(data, file)\n",
    "\n",
    "'''\n",
    "author = Author('Mehrad Ansari')\n",
    "pub = Publication(author.get_last_publication())\n",
    "\n",
    "pub.download_pdf('pdfs/')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc875ae1-baaf-468b-99ed-bd2dd9bde049",
   "metadata": {},
   "source": [
    "## Main module to test function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa3679f7-7f70-4168-a95e-5a07f34f01dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nllm = Bot_LLM()\\n\\n\\nauthor = Author(\\'Mehrad Ansari\\')\\n\\nprint(\"Author object created successfully \\n \\n\")\\n\\npub = Publication(author.get_last_publication())\\n\\n\\nprint(\"Publication object created successfully - Having fetched the last publication \\n \\n\")\\n\\nprint(\\'current available attributes: \\n \\n\\')\\nprint(pub)\\n\\nprint(\\'\\n \\nRunning LLM on the abstract of the publication \\n \\n\\')\\npub.get_topic(llm=llm)\\nprint(\\'current available attributes: \\n \\n\\')\\nprint(pub)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the LLM\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "llm = Bot_LLM()\n",
    "\n",
    "\n",
    "author = Author('Mehrad Ansari')\n",
    "\n",
    "print(\"Author object created successfully \\n \\n\")\n",
    "\n",
    "pub = Publication(author.get_last_publication())\n",
    "\n",
    "\n",
    "print(\"Publication object created successfully - Having fetched the last publication \\n \\n\")\n",
    "\n",
    "print('current available attributes: \\n \\n')\n",
    "print(pub)\n",
    "\n",
    "print('\\n \\nRunning LLM on the abstract of the publication \\n \\n')\n",
    "pub.get_topic(llm=llm)\n",
    "print('current available attributes: \\n \\n')\n",
    "print(pub)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208054f8",
   "metadata": {},
   "source": [
    "### Getting PDF - Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9d213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n# Fetching PDF\\n\\ndef check_and_create_directory(path):\\n    \\n    if not os.path.exists(path):\\n        # If it doesn\\'t exist, create the directory\\n        os.makedirs(path)\\n        print(f\"Directory {path} created.\")\\n    else:\\n        print(f\"Directory {path} already exists.\")\\n\\n\\npub.get_pdf()\\nprint(\\'current available attributes: \\n \\n\\')\\nprint(pub)\\n\\n# Downloading PDF\\ncurrent_directory = os.getcwd()\\n\\nprint(f\"The current working directory is: {current_directory}\")\\n\\npath = current_directory + \\'/pdfs/\\'\\n\\ncheck_and_create_directory(path)\\n\\npub.download_pdf(path)\\n\\nprint(pub)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "# Fetching PDF\n",
    "\n",
    "def check_and_create_directory(path):\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        # If it doesn't exist, create the directory\n",
    "        os.makedirs(path)\n",
    "        print(f\"Directory {path} created.\")\n",
    "    else:\n",
    "        print(f\"Directory {path} already exists.\")\n",
    "\n",
    "\n",
    "pub.get_pdf()\n",
    "print('current available attributes: \\n \\n')\n",
    "print(pub)\n",
    "\n",
    "# Downloading PDF\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "print(f\"The current working directory is: {current_directory}\")\n",
    "\n",
    "path = current_directory + '/pdfs/'\n",
    "\n",
    "check_and_create_directory(path)\n",
    "\n",
    "pub.download_pdf(path)\n",
    "\n",
    "print(pub)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd88614",
   "metadata": {},
   "source": [
    "### Feeding it to the LLM\n",
    "\n",
    "We're Checking first if we got the PDF already; we're feeding it to the LLM. If we don't we give it the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ecb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/cell_penetration_of_oxadiazole_containing_macrocycles.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/DNA-encoded library-enabled discovery of proximity-inducing small molecules.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/photoresponsive_organic_cages_computationally_driven_discovery_of_azobenzene_derived_organic_cages.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Big_data_and_benchmarking_initiatives_to_bridge_the_gap_from_AlphaFold_to_drug_design.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/evaluating_the_feasibility_of_medium_chain_oleochemical_synthesis_using_microbial_chain_elongation.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Enhanced_sampling_of_robust_molecular_datasets_with_uncertainty-based_collective_variables.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/degradable_conjugated_polymers.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/language_models_can_identify_enzymatic_binding_sites_in_protein_sequences.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Probing_out-of-distribution_generalization_in_machine_learning_for_materials.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/quest_self_supervised_skill_abstractions_for_learning_continuous_control.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/holistic_platform_for_accelerating_sorbent-based_carbon_capture.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/history-agnostic-battery-degradation-inference (1).pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Structure-guided_drug_discovery_back_to_the_future.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Flipping_the_script_Understanding_riboswitches_from_an_alternative_perspective.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/efficient_multicarbon_formation_in_acidic_CO2_reduction_via_tandem_electrocatalysis.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/A_chemical_probe_to_modulate_human_GID4_Pro_N-degron_interactions.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/JARVIS-Leaderboard_a_large_scale_benchmark_of_materials_design_methods.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/closing_the_execution_gap_in_generative_ai_for_chemicals_and_materials_freeways_or_safeguards.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/navigating_the_materials_space_with_ml_generated_electronic_fingerprints.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/enhancing_protein_ligand_binding_affinity_predictions_using_neural_network_potentials.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/understanding_causalities_in_organic_photovoltaics_device_degradation_in_a_machine_learning_driven_high_throughput_platform.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/ru_doped_functional_porous_materials_for_electrocatalytic_water_splitting.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/A_ligand_discovery_toolbox_for_the_WWE_domain_family_of_human_E3_ligases.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/term_sheets_in_venture_capital.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/History-agnostic battery degradation inference.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/towards_comprehensive_coverage_of_chemical_space_quantum_mechanical_properties_of_836k_constitutional_and_conformational_closed_shell_neutral_isomers_consisting_of_hcnofsipsclbr.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/reactive_carbon_capture_enables_co2_electrolysis_with_liquid_feedstocks.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/delocalized_asynchronous_closed_loop_discovery_of_organic_laser_emitters.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Assessment_of_chemistry_knowledge_in_large_language_models_that_generate_code.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/inverse_design_of_porous_materials_a_diffusion_model_approach.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/investigating_the_influence_of_treatments_on_carbon_felts_for_vanadium_redox_flow_batteries.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/ansari-white-2023-serverless-prediction-of-peptide-properties-with-recurrent-neural-networks.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Correction_to_Up-regulation_of_autophagy_is_a_mechanism_of_resistance_to_chemotherapy_and_can_be_inhibited_by_pantoprazole_to_increase_drug_sensitivity.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/A_data-driven_framework_to_improve_the_wear_resistance_of_a_low-alloy_steel_fabricated_by_laser_powder_bed_fusion.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Accurate_predictions_of_keyhole_depths_using_machine_learning-aided_simulations.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/synergistic_effects_of_thermosensitive_liposomal_doxorubicin_mild_hyperthermia_and_radiotherapy_in_breast_cancer_management_an_orthotopic_mouse_model_study.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Exploiting_redundancy_in_large_materials_datasets_for_efficient_machine_learning_with_less_data.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Artificial_Intelligence-Enabled_Optimization_of_Battery-Grade_Lithium_Carbonate_Production.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/accelerated_chemical_science_with_ai.pdf done\n",
      "benchmarking() missing 1 required positional argument: 'index'\n",
      "pdfs/Efficient_first_principles_based_modeling_via_machine_learning_from_simple_representations_to_high_entropy_materials.pdf done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def benchmarking(file, index):    \n",
    "    llm = Bot_LLM(folder_path='db/db'+str(index))\n",
    "    llm.chunk_indexing(file)    \n",
    "    #llm.folder_path = txt\n",
    "    dico = {}\n",
    "    ## Querying the RAG\n",
    "    dico['affiliation'] = llm.query_rag(\"What are the authors affiliation. Output a dictionary ?\")\n",
    "    print(\"-----\")\n",
    "    dico['topic']  = llm.query_rag(\"What are topics of the paper ?\")\n",
    "    \n",
    "    print(\"-----\")\n",
    "    dico['new materials'] = llm.query_rag(\"does the article mention any new material discovery ?\")\n",
    "    print(\"-----\")\n",
    "    dico['screening algorithms'] = llm.query_rag(\"A screening algorithm is a systematic procedure or method used to identify individuals who may have or be at risk for a particular condition or trait within a large population. These algorithms are designed to quickly and efficiently screen out those who are unlikely to have the condition, while identifying those who may require further diagnostic evaluation or intervention. If there are any, What are the screening algorithms used in the paper ?\")\n",
    "    print(\"-----\")\n",
    "    dico['AI algorithms'] = llm.query_rag(\"AI algorithms are computational methods and processes used to solve specific tasks by mimicking human intelligence. These algorithms enable machines to learn from data, make decisions, and perform tasks that typically require human intelligence.\")\n",
    "    print(\"-----\")\n",
    "    \n",
    "    dico['workflow'] = llm.query_rag(\"Can you describe to me the workflow used by the author ?\")\n",
    "    print(\"-----\")\n",
    "    dico['methods'] = llm.query_rag(\"can you do a methods description ?\")\n",
    "    print(\"-----\")\n",
    "    dico['models'] = llm.query_rag(\"what are the models used in the article ?\")\n",
    "    print(\"-----\")\n",
    "    dico['funding'] = llm.query_rag(\"does the article mention who funded it\")\n",
    "    print(\"-----\")\n",
    "    print(dico)\n",
    "    return dico\n",
    "\n",
    "\n",
    "import glob\n",
    "files_in_dir = glob.glob('pdfs'+ \"/*\")\n",
    "dico_response = {}\n",
    "\n",
    "def load_json_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "dico_response = load_json_data('benchmarking.json')\n",
    "for index,file in enumerate(files_in_dir):\n",
    "    print(index,file)\n",
    "    try:\n",
    "        if file not in dico_response:\n",
    "            dico_response[file.split('/')[1]] = benchmarking(file,index)\n",
    "        else:\n",
    "            print(\"file already done\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        dico_response[file.split('/')[1]] = None\n",
    "    print(file+\" done\")\n",
    "        \n",
    "with open('benchmarking1.json', 'w') as json_file:\n",
    "    json.dump(dico_response, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf635b-9783-4970-8cc2-fdd9b9a5d38a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
