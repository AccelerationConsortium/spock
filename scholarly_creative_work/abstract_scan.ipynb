{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Abstracts Using a Large Language Model (LLM)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this Jupyter Notebook, we will perform an in-depth analysis of abstracts extracted from a CSV file using a Large Language Model (LLM). The goal of this analysis is to leverage the capabilities of LLMs to extract meaningful insights, identify key themes, and perform various natural language processing (NLP) tasks on the abstracts.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- **Data Loading**: Import and preprocess abstracts from a CSV file.\n",
    "- **Text Analysis**: Utilize LLMs to analyze the content of the abstracts.\n",
    "\n",
    "### Tools and Libraries\n",
    "\n",
    "- **LangChain**: To interface with the LLM.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. **Data Import**: Load the CSV file containing the abstracts.\n",
    "3. **LLM Integration**: Use the LLM to perform various NLP tasks.\n",
    "\n",
    "By the end of this notebook, you will have a comprehensive understanding of how to use LLMs for analyzing textual data and extracting valuable insights from scientific abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Import**: Load the CSV file containing the abstracts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from downloader import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:58\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:58\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:58\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:35:58\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:58\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:58\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88628e9910>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f886291f710>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f886227e890>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:35:59\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1038/s41586-020-2746-2], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f886229cc50>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1038/s41586-020-2746-2. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1038/s41586-020-2746-2\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862297a50>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:00\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862297790>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88634cc910>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1186/s12885-016-2539-z], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f886227e710>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1186/s12885-016-2539-z. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1186/s12885-016-2539-z\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:01\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862231c10>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88622e5950>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88622e7c50>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1038/nmeth.2895], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88621164d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1038/nmeth.2895. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:02\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1038/nmeth.2895\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:03\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88628e4e50>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88620fc6d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88620fd2d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1016/j.celrep.2012.09.016], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88629f2310>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1016/j.celrep.2012.09.016. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1016/j.celrep.2012.09.016\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:04\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88622a5950>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88621357d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862136490>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1158/1535-7163.MCT-09-0495], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862100e90>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1158/1535-7163.MCT-09-0495. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:05\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1158/1535-7163.MCT-09-0495\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862294f90>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88622969d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88628d5650>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:06\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1182/blood-2009-07-231191], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862115650>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1182/blood-2009-07-231191. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1182/blood-2009-07-231191\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:07\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862162e10>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88622a6590>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88628d7690>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1038/nmeth.3472], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862161990>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1038/nmeth.3472. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1038/nmeth.3472\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:08\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88628d00d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88628dcc50>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f886227ff90>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1074/jbc.M113.469262], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862179310>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1074/jbc.M113.469262. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:09\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1074/jbc.M113.469262\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1mChoose scihub url [3]: http://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.se, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.se', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f886213d590>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1mChoose scihub url [4]: http://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.ru, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.ru', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f8862177d90>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1mChoose scihub url [5]: http://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.mobi, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.mobi', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88621342d0>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1mChoose scihub url [6]: https://sci-hub.se\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:10\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.se, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1mChoose scihub url [7]: http://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1m<- Request: scihub_url=http://sci-hub.st, source=DoiSource[type=doi, id=10.1016/j.molcel.2005.02.029], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: SOCKSHTTPConnectionPool(host='sci-hub.st', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSConnection object at 0x7f88620fdb90>: Failed to establish a new connection: [Errno 111] Connection refused'))\u001b[0m\n",
      "\u001b[31m\u001b[1m[ERROR]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[31m\u001b[1mFailed to download the paper: 10.1016/j.molcel.2005.02.029. Please try again.\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1mChoose scihub url [0]: https://sci-hub.st\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.st, source=DoiSource[type=doi, id=10.1074/jbc.M307200200], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf not found for 10.1016/j.molcel.2005.02.029\n",
      "[]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1m-> Response: status_code=200, content_length=0\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: extracting_failed, error: No pdf tag was found in the given content with the selector: #pdf\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1mChoose scihub url [1]: https://sci-hub.mobi\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.mobi, source=DoiSource[type=doi, id=10.1074/jbc.M307200200], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n",
      "\u001b[33m\u001b[1m[WARNING]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[33m\u001b[1mError occurs, task status: crawling_failed, error: HTTPSConnectionPool(host='sci-hub.mobi', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1006)')))\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1mChoose scihub url [2]: https://sci-hub.ru\u001b[0m\n",
      "\u001b[1m[INFO]\u001b[0m | \u001b[32m2024/09/10 20:36:11\u001b[0m | \u001b[1m<- Request: scihub_url=https://sci-hub.ru, source=DoiSource[type=doi, id=10.1074/jbc.M307200200], proxies={'http': 'socks5://127.0.0.1:7890'}\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall(Scholarly & creative works_Obje).csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m num_lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 25\u001b[0m dico \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_lines\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(file_path, num_lines)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     downloader \u001b[38;5;241m=\u001b[39m Downloader(row[\u001b[38;5;241m17\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdfs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;241m17\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mdownloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     dico[row[\u001b[38;5;241m17\u001b[39m]]\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/clone/spock/scholarly_creative_work/downloader.py:25\u001b[0m, in \u001b[0;36mDownloader.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(folder_paths)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mscihub_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaper_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaper_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;241m==\u001b[39m folder_paths:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaper)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scidownl/api/scihub.py:37\u001b[0m, in \u001b[0;36mscihub_download\u001b[0;34m(keyword, paper_type, scihub_url, out, proxies)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Download a paper from SciHub.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m:param keyword: a DOI or a PMID.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    name of the paper's title.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     30\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mScihubTask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_keyword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaper_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscihub_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscihub_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\n\u001b[0;32m---> 37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scidownl/core/task.py:58\u001b[0m, in \u001b[0;36mScihubTask.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChoose scihub url [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscihub_url\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscihub_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     60\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurs, task status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scidownl/core/task.py:67\u001b[0m, in \u001b[0;36mScihubTask._run\u001b[0;34m(self, scihub_url)\u001b[0m\n\u001b[1;32m     65\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_keyword)\n\u001b[1;32m     66\u001b[0m crawler \u001b[38;5;241m=\u001b[39m ScihubCrawler(source, scihub_url, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[43mcrawler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m extractor \u001b[38;5;241m=\u001b[39m HtmlPdfExtractor(content, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     70\u001b[0m pdf_url_title_info \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mextract()\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scidownl/core/crawler.py:39\u001b[0m, in \u001b[0;36mScihubCrawler.crawl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m proxies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\u001b[38;5;241m.\u001b[39mcontext\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxies\u001b[39m\u001b[38;5;124m'\u001b[39m, {}) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<- Request: scihub_url=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscihub_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, source=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, proxies=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproxies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscihub_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-> Response: status_code=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, content_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ScihubCrawler\u001b[38;5;241m.\u001b[39mOK_STATUS_CODES:\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def read_csv(file_path, num_lines):\n",
    "    with open(file_path, 'r', encoding=\"utf8\", errors='ignore') as file:\n",
    "        reader = csv.reader(file)\n",
    "        dico = {}\n",
    "        for i, row in enumerate(reader):\n",
    "            if i >= num_lines:\n",
    "                break\n",
    "            if i == 0:\n",
    "                continue\n",
    "            dico[row[17]] = {\"abstract\": row[4]} \n",
    "            try:\n",
    "               \n",
    "                downloader = Downloader(row[17], 'doi', f\"pdfs/{row[17]}.pdf\")\n",
    "                downloader.download()\n",
    "                dico[row[17]].update({\"pdf\": True})\n",
    "            except Exception as e:\n",
    "                dico[row[17]].update({\"pdf\": False})\n",
    "                print(e)\n",
    "                \n",
    "        print(dico)\n",
    "        return dico\n",
    "\n",
    "file_path = \"all(Scholarly & creative works_Obje).csv\"\n",
    "num_lines = 100\n",
    "dico = read_csv(file_path, num_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MACHINE LEARNING': [], 'BATTERIES': ['batteries'], 'AI': [], 'ACCELERATED MATERIALS DISCOVERY': ['materials discovery'], 'SELF DRIVING LABS': [], 'AUTONOMOUS LABS': [], 'HIGH-THROUGHPUT EXPERIMENTATION': ['high-throughput experimentation', 'high-throughput DFT']}\n"
     ]
    }
   ],
   "source": [
    "def get_topic(abstract:str):\n",
    "    \n",
    "    Llm = Ollama(model='llama3', temperature=0.2)\n",
    "    \n",
    "    \n",
    "    if abstract is None:\n",
    "        raise ValueError(\"Abstract is required\")\n",
    "    \n",
    "    parser = JsonOutputParser()\n",
    "    \n",
    "    #AI / accelerated materials discovery / SDLs / autonomous labs / high-throughput experimentation / high-throughput DFT\n",
    "    \n",
    "    topics = [\"Machine Learning\", \"Batteries\", \"AI\", \"accelerated materials discovery\", \"Self Driving Labs\", \"autonomous labs\", \"high-throughput experimentation\", \"high-throughput DFT\"]\n",
    "    \n",
    "    \n",
    "    new_text = \"\"\"\n",
    "    \n",
    "    The output needs to be formated as the following: \n",
    "    \n",
    "    {\n",
    "    \"topic\": {\n",
    "    \"topic1\": [\"Keyword1\", \"Keyword2\", \"Keyword3\"],\n",
    "    \"topic2\": [\"Keyword1\", \"Keyword2\", \"Keyword3\"]\n",
    "    }\n",
    "    }\n",
    "    \n",
    "    Only output the dictionary above, nothing else with it.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "    template=\" So you are a text assistant and I need you to help me identify the topics from the following list the text given to you {topics}. \\n Here's the text: {abstract}. \\n\\n Note: A single text can belong to multiple topics, so please list all relevant topics. {format_instructions}\",\n",
    "    input_variables=[\"format_instructions\", \"abstract\", \"topics\"]\n",
    "    )\n",
    "\n",
    "    chain = prompt | Llm | parser\n",
    "    topics = chain.invoke({\"format_instructions\": new_text, \"abstract\": abstract, \"topics\": topics})\n",
    "    return list(topics.values())[0]\n",
    "\n",
    "\n",
    "print(get_topic(\"The development of high-performance batteries is crucial for the future of electric vehicles. The current generation of batteries are not able to provide the range and power required for long-distance travel. This project aims to develop new materials for batteries that can provide higher energy density and faster charging times.\"))\n",
    "\n",
    "def get_info(abstract:str = None, **kwargs):\n",
    "    Llm = Ollama(model='llama3', temperature=0.5)\n",
    "    if abstract is None:\n",
    "        raise ValueError(\"Abstract is required\")\n",
    "    \n",
    "    dico = {}\n",
    "    for key, question in kwargs.items():\n",
    "        print(key, question)\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"So you are a text assistant and I want you to assist me by providing the following information: {question}. \\n\\n Here's the text: {abstract}. \\n\\n If the text doesn't contain any information about the topic given, output: 'N/A'\",\n",
    "            input_variables=[\"abstract\", \"question\"]\n",
    "        )\n",
    "        chain = prompt | Llm \n",
    "        info = chain.invoke({\"abstract\": abstract, \"question\": question})\n",
    "        dico[key] = info\n",
    "    print(dico)\n",
    "    return dico\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here is the information you requested:\\n\\nThe authors of the text are not explicitly mentioned. However, the characters in the text can be categorized as follows:\\n\\n* Cancer cells\\n* Cytotoxic T-lymphocytes (CTLs)\\n* Mouse cancer cell lines\\n* Genes and pathways involved in cancer evasion (e.g., Ptpn2, Socs1, Adar1, Fitm2, autophagy pathway)\\n\\nPlease note that these are not affiliations in the classical sense but rather entities mentioned in the text.', 'new_materials': 'The text mentions several new discoveries:\\n\\n* The identification of a core set of 182 genes across mouse cancer models that enable cancer cells to evade killing mediated by cytotoxic T-lymphocytes (CTLs)\\n* The establishment of a central role for previously identified negative regulators of the type-II interferon response in mediating CTL evasion\\n* The discovery of Fitm2, a lipid-droplet-related gene required for maintaining cell fitness after exposure to interferon-?\\n* The identification of the autophagy pathway as a conserved mediator of the evasion of CTLs by cancer cells\\n\\nThese findings expand our knowledge of the genetic circuits involved in the evasion of the immune system by cancer cells.', 'screening_algorithms': 'Yes, there is screening algorithm or systematic procedure discussed in the text. The authors performed genome-wide CRISPR screens across a panel of genetically diverse mouse cancer cell lines to identify a core set of genes and pathways that enable cancer cells to evade killing mediated by cytotoxic T-lymphocytes (CTLs). Additionally, they used systematic exploration of their dataset using genetic co-similarity to reveal the hierarchical and coordinated manner in which genes and pathways act in cancer cells to orchestrate their evasion of CTLs.', 'ai_algorithms': 'The text does not reference any AI algorithms or methods related to artificial intelligence. Therefore, my answer is N/A.', 'workflow': 'The workflow or process followed in this text can be summarized as follows:\\n\\n1. Genome-wide CRISPR screens were performed across a panel of genetically diverse mouse cancer cell lines that were cultured in the presence of cytotoxic T lymphocytes (CTLs).\\n2. The screens aimed to identify a core set of genes and pathways that enable cancer cells to evade killing mediated by CTLs.\\n3. The data from the screens was analyzed to identify individual perturbations that increase either the sensitivity or resistance of cancer cells to CTL-mediated toxicity.\\n4. Systematic exploration of the dataset using genetic co-similarity revealed the hierarchical and coordinated manner in which genes and pathways act in cancer cells to orchestrate their evasion of CTLs.\\n5. The data was used to establish a central role for certain genes in mediating CTL evasion, identify autophagy as a conserved mediator of evasion, and show how autophagy controls cancer-cell-intrinsic evasion of killing by CTLs.\\n6. In vivo CRISPR screens were performed to map cytokine- and CTL-based genetic interactions.\\n\\nOverall, the workflow involved using CRISPR screens to identify genes and pathways that enable cancer cells to evade the immune system, followed by analysis and interpretation of the data to understand the underlying mechanisms.', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n1. Genome-wide CRISPR screens\\n2. Systematic exploration of dataset using genetic co-similarity\\n3. Mapping of cytokine- and CTL-based genetic interactions\\n4. In vivo CRISPR screens\\n\\nThese methods were used to identify a core set of genes and pathways that enable cancer cells to evade killing mediated by cytotoxic T lymphocytes (CTLs).', 'models': \"The models or frameworks discussed or used in this text are:\\n\\n* CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) screens\\n* Genetic co-similarity framework\\n* Autophagy pathway model\\n* Type-II interferon response model\\n* TNF-induced cytotoxicity model\\n\\nSo, the answer is not 'N/A'!\", 'funding': 'N/A'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors do not have any affiliations explicitly stated in this text. However, it is common practice for researchers to include their affiliations (e.g., institutions, universities, research centers) at the end of an article or paper.\\n* The characters (in this case, patients with clear cell renal cell carcinoma and normal kidney epithelial cells) do not have any affiliations mentioned in this text.', 'new_materials': 'The text mentions new materials or discoveries in the following points:\\n\\n* The ability to establish primary cultures of ccRCC cells with an efficiency of >80% using purification of cells based on expression of carbonic anhydrase IX (CA9) and culture in FBS.\\n* The development of a resource for future development of novel therapies and personalized medicine for ccRCC patients.\\n\\nSo, the answer is: Yes, the text mentions new materials or discoveries.', 'screening_algorithms': 'After reviewing the provided text, I found that there are no specific screening algorithms or systematic procedures discussed. The text primarily focuses on the methodology used to establish primary cell cultures of clear cell renal cell carcinoma (ccRCC) and matched normal kidney epithelial cells.\\n\\nSo, the answer is: N/A', 'ai_algorithms': 'Based on the provided text, I did not find any direct references to AI algorithms or methods related to artificial intelligence. Therefore, my answer is:\\n\\nN/A', 'workflow': 'Based on the provided text, the workflow or process followed is:\\n\\n1. Generation of primary single cell suspensions from clear cell renal cell carcinoma (ccRCC) tumor tissues.\\n2. Culture of these suspensions in fetal bovine serum (FBS)-containing media or defined serum-free media.\\n3. Characterization of established cultures by:\\n\\t* Genomic verification of mutations present in the primary tumors.\\n\\t* Expression of renal epithelial markers.\\n\\t* Transcriptional profiling.\\n4. Purification of cells based on expression of carbonic anhydrase IX (CA9), a cell surface hypoxia-inducible factor (HIF) target, to establish ccRCC cell cultures with high efficiency (>80%).\\n5. Culture in serum-free conditions to select for growth of normal renal proximal tubule epithelial cells.\\n6. Transcriptional profiling of ccRCC and matched normal cell cultures to identify up- and down-regulated networks in ccRCC and compare to The Cancer Genome Atlas (TCGA) data.\\n\\nPlease note that this process is specific to the establishment of primary cultures of ccRCC cells from patient tumor tissues, and may not be applicable to other research topics or areas.', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n1. Primary cell suspension culture using fetal bovine serum (FBS)-containing media or defined serum-free media.\\n2. Genomic verification of mutations present in primary tumors to characterize established cultures.\\n3. Expression of renal epithelial markers to confirm the identity of cultured cells.\\n4. Transcriptional profiling to analyze gene expression patterns in ccRCC and matched normal cell cultures.\\n5. Purification of cells based on expression of carbonic anhydrase IX (CA9), a cell surface HIF target, to establish ccRCC cell cultures.\\n\\nThese methods were used to generate accurate preclinical in vitro models of clear cell renal cell carcinoma (ccRCC) using tumor tissues from patients with ccRCC.', 'models': 'The models or frameworks discussed in this text are:\\n\\n* The Cancer Genome Atlas (TCGA)\\n\\nAdditionally, the text mentions several biological pathways and processes, including:\\n\\n* Hypoxia-inducible factor (HIF) pathway\\n* Von Hippel Lindau (VHL) gene regulation\\n* Carbonic anhydrase IX (CA9) as a cell surface marker for ccRCC cells\\n\\nHowever, there are no specific statistical or analytical frameworks mentioned in the text.', 'funding': 'N/A'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors/characters in the text do not have explicit affiliations mentioned. However, it is noted that the study was published in Nature America, Inc., which suggests an affiliation with the journal.\\n\\nOutput: N/A (since there are no explicit author or character affiliations mentioned)', 'new_materials': 'According to the provided text, there are no new materials or discoveries mentioned. The text discusses a method for detecting interactions between membrane proteins (MaMTH) and its applications in understanding cellular signaling processes, but it does not introduce any novel materials or discoveries. Therefore, the answer is: N/A.', 'screening_algorithms': 'According to the provided text, yes, there are screening algorithms or systematic procedures discussed. Specifically, the text mentions a \"split ubiquitin-based method\" called MaMTH (mammalian-membrane two-hybrid assay) that can be used as a screening assay for detecting protein-protein interactions and changes in these interactions conferred by mutations or treatments.', 'ai_algorithms': 'The answer is: N/A\\n\\nThere are no references to AI algorithms or methods related to artificial intelligence in this text. The text discusses a biological method for detecting protein-protein interactions called MaMTH (mammalian-membrane two-hybrid assay) and its application in studying cell signaling pathways.', 'workflow': 'Based on the provided text, I can describe the workflow or process followed as:\\n\\n1. Detection of integral membrane protein-protein interactions (PPIs) using a split ubiquitin-based method called mammalian-membrane two-hybrid assay (MaMTH).\\n2. MaMTH detects stimulus-dependent and phosphorylation-dependent PPIs in human cells.\\n3. The technology can detect changes in PPIs conferred by:\\n\\t* Mutations, such as those in oncogenic ErbB receptor variants\\n\\t* Treatment with drugs, such as the tyrosine kinase inhibitor erlotinib\\n4. MaMTH is used as a screening assay to identify interactors of specific proteins or to investigate dynamic interactomes of human integral membrane proteins.\\n\\nLet me know if you have any further questions!', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n* Split ubiquitin-based method\\n* Mammalian-membrane two-hybrid assay (MaMTH)\\n* Screening assay using MaMTH as a tool for investigating the dynamic interactomes of human integral membrane proteins.\\n\\nLet me know if you need any further assistance!', 'models': 'The models or frameworks discussed in this text are:\\n\\n* Split ubiquitin-based method\\n* Mammalian-membrane two-hybrid assay (MaMTH)\\n\\nThese models or frameworks are used to detect and study protein-protein interactions (PPIs) in human cells.', 'funding': 'The text does not mention any specific funding sources or sponsors. Therefore, my answer is: N/A'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* Authors:\\n\\t+ N/A (no specific authors or affiliations mentioned)\\n* Characters/Proteins:\\n\\t+ CD133: a membrane glycoprotein\\n\\t+ HDAC6: deacetylase protein\\n\\t+ ?-catenin: central molecule of the canonical Wnt signaling pathway\\n\\nLet me know if you have any further questions!', 'new_materials': 'According to the text, there is no mention of new materials or discoveries. Therefore, my answer would be:\\n\\nN/A', 'screening_algorithms': 'Yes, there are screening algorithms or systematic procedures discussed in the text.\\n\\nSpecifically, the text mentions:\\n\\n* The physical association of HDAC6 with CD133 and ?-catenin\\n* The regulation of CD133 trafficking down the endosomal-lysosomal pathway for degradation by HDAC6\\n* The stabilization of ?-catenin via HDAC6 deacetylase activity leading to activation of ?-catenin signaling targets\\n* The correlation between CD133/HDAC6 downregulation and increased ?-catenin acetylation and degradation, which affects proliferation in vitro and tumor xenograft growth in vivo.\\n\\nThese findings suggest a systematic procedure for understanding the molecular function and regulation of CD133, as well as its potential role in cancer development and treatment.', 'ai_algorithms': 'Based on the provided text, I found no reference to AI algorithms or methods related to artificial intelligence. Therefore, my answer is:\\n\\nN/A', 'workflow': \"Based on the provided text, I can describe the workflow or process as follows:\\n\\n1. Introduction: The text introduces the protein CD133 and its role in marking lineage-specific cancer progenitor cells.\\n2. Research question: The authors investigate the regulation of CD133 protein and its molecular function.\\n3. Findings:\\n\\t* The deacetylase HDAC6 physically associates with CD133 to negatively regulate CD133 trafficking down the endosomal-lysosomal pathway for degradation.\\n\\t* CD133, HDAC6, and ?-catenin (a central molecule in the canonical Wnt signaling pathway) can physically associate as a ternary complex.\\n\\t* This association stabilizes ?-catenin via HDAC6 deacetylase activity, leading to activation of ?-catenin signaling targets.\\n4. Consequences:\\n\\t* Downregulation of either CD133 or HDAC6 results in increased ?-catenin acetylation and degradation.\\n\\t* Decreased proliferation is observed in vitro and tumor xenograft growth in vivo.\\n5. Conclusion: The study suggests that targeting CD133 may be a means to treat multiple cancer types.\\n\\nPlease let me know if you have any further questions or if there's anything else I can assist you with!\", 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* Physical association studies to identify interactions between proteins (CD133, HDAC6, and ?-catenin)\\n* Cellular assays (in vitro) to study the effects of CD133 and HDAC6 regulation on ?-catenin signaling targets\\n* Xenograft growth experiments (in vivo) to evaluate the impact of CD133 and HDAC6 downregulation on tumor growth\\n\\nThese methods were used to investigate the molecular function and regulation of CD133, as well as its potential role in cancer development and treatment.', 'models': 'The models or frameworks discussed or used in this text are:\\n\\n* Canonical Wnt signaling pathway\\n* Endosomal-lysosomal pathway for degradation\\n\\nSo, the answer is not \"N/A\"!', 'funding': 'N/A'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors of the study are not explicitly stated in the text.\\n* The AACR (American Association for Cancer Research) is mentioned as the publisher of the study, but no specific affiliation is given.\\n\\nSo, the output would be:\\n\\nN/A', 'new_materials': 'According to the provided text, YES, it mentions new materials or discoveries. Specifically:\\n\\n* A small-molecule compound called droxinostat (4-(4-chloro-2-methylphenoxy)-N-hydroxybutanamide) was identified as a chemical sensitizer to death receptor stimuli.\\n* The mechanism of action of droxinostat was found to involve the selective inhibition of HDAC3, HDAC6, and HDAC8 enzymes.\\n\\nSo, there are new materials (droxinostat) and discoveries (mechanism of action) mentioned in the text.', 'screening_algorithms': 'According to the text, yes, there are screening algorithms or systematic procedures discussed. Specifically, the authors mention using the Connectivity Map to analyze changes in gene expression after treating cells with droxinostat. Additionally, they discuss the effects of droxinostat on HDAC activity and examine the functional importance of inhibiting specific HDACs for its ability to sensitize cells to death ligands.', 'ai_algorithms': \"The text references AI algorithms or methods related to artificial intelligence.\\n\\nSpecifically, it mentions the use of the Connectivity Map, which is a computational tool that uses gene expression data to identify patterns and relationships between different biological pathways. This suggests that the authors used some form of bioinformatics analysis to analyze changes in gene expression after treating cells with droxinostat.\\n\\nTherefore, I would output: 'Yes'\", 'workflow': \"The workflow or process followed in this text can be described as follows:\\n\\n1. Identification of a molecule (droxinostat) that restores sensitivity to death receptor stimuli and decreases expression of FLIP.\\n2. Analysis of changes in gene expression using the Connectivity Map after treating cells with droxinostat.\\n3. Comparison of results from step 2 with changes observed after treatment with histone deacetylase (HDAC) inhibitors, leading to a hypothesis about the mechanism of action of droxinostat.\\n4. Examination of the effects of droxinostat on HDAC activity and identification of specific HDACs (HDAC3, HDAC6, and HDAC8) that are inhibited by droxinostat.\\n5. Functional analysis of the importance of inhibiting these HDACs for droxinostat's ability to sensitize cells to death ligands.\\n\\nOverall, the process involves a combination of molecular biology techniques, including gene expression analysis and enzyme activity assays, as well as functional studies to understand the mechanism of action of a small molecule (droxinostat).\", 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* Analyzing changes in gene expression using the Connectivity Map after treating cells with droxinostat\\n* Examining the effects of droxinostat on HDAC activity\\n* Inhibiting specific HDACs (HDAC3, HDAC6, and HDAC8) to study their functional importance in sensitizing cells to death ligands\\n\\nLet me know if you have any further questions!', 'models': 'The models or frameworks discussed in this text are:\\n\\n* The Connectivity Map\\n* Histone deacetylase (HDAC) inhibitors\\n\\nThese frameworks are used to analyze changes in gene expression and understand the mechanism of action of droxinostat.', 'funding': 'The text does not mention any specific funding sources or sponsors. Therefore, my answer is \"N/A\".'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'The authors or characters in this text have the following affiliations:\\n\\n* Authors: N/A (the text does not mention specific authors or their affiliations)\\n* Characters: None (this is a scientific article and does not involve fictional characters)\\n\\nHowever, the text mentions the American Society of Hematology as the copyright holder.', 'new_materials': 'The text mentions a novel small molecule inhibitor called PYZD-4409, which is a 3,5-dioxopyrazolidine compound. Therefore, the answer is:\\n\\nYES', 'screening_algorithms': 'Yes, there are screening algorithms or systematic procedures discussed in the text.\\n\\nThe text mentions several systematic procedures:\\n\\n1. Immunoblotting to evaluate protein ubiquitination.\\n2. Knockdown of E1 enzyme to examine its effects on ubiquitinated proteins and cell death.\\n3. Inhibition of E1 enzyme using a small molecule inhibitor (PYZD-4409) to investigate its effects on malignant cells and normal hematopoietic cells.\\n4. Overexpression of BI-1 to block cell death after E1 inhibition.\\n\\nThese procedures are used to systematically evaluate the effects of inhibiting the ubiquitination pathway at the level of the ubiquitin-activating enzyme UBA1 (E1) in leukemia and myeloma cells, as well as in a mouse model of leukemia.', 'ai_algorithms': 'The text does not reference any AI algorithms or methods related to artificial intelligence. Therefore, the answer is N/A.', 'workflow': 'Based on the provided text, the workflow or process followed can be described as follows:\\n\\n1. Introduction to the proteasomal pathway of protein degradation and its two discrete steps: ubiquitination and degradation.\\n2. Evaluation of the effects of inhibiting the ubiquitin-activating enzyme UBA1 (E1) at the level of E1.\\n3. Immunoblotting analysis to examine the levels of ubiquitinated proteins in leukemia cell lines and primary patient samples, revealing increased protein ubiquitination.\\n4. Genetic and chemical inhibition of the E1 enzyme:\\n\\t* Knockdown of E1 decreased the abundance of ubiquitinated proteins in leukemia and myeloma cells and induced cell death.\\n5. Discovery of a novel small molecule inhibitor, PYZD-4409, which:\\n\\t* Induced cell death in malignant cells\\n\\t* Preferentially inhibited the clonogenic growth of primary acute myeloid leukemia cells compared with normal hematopoietic cells\\n6. Mechanistic studies:\\n\\t* Genetic or chemical inhibition of E1 increased expression of E1 stress markers\\n\\t* Overexpression of BI-1 blocked cell death after E1 inhibition, suggesting ER stress is functionally important for cell death after E1 inhibition\\n7. In vivo study:\\n\\t* Intraperitoneal administration of PYZD-4409 decreased tumor weight and volume in a mouse model of leukemia without untoward toxicity\\n\\nOverall, the text describes the discovery of a novel target (E1 enzyme) and its potential as a therapeutic approach for treating hematologic malignancies.', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n* Immunoblotting\\n* Genetic inhibition (knockdown) of the ubiquitin-activating enzyme UBA1 (E1)\\n* Chemical inhibition using a small molecule inhibitor, 3,5-dioxopyrazolidine compound, 1-(3-chloro-4-fluorophenyl)-4-[(5-nitro-2-furyl)methylene]-3, 5-pyrazolidinedione (PYZD-4409)\\n* Overexpression of BI-1\\n* In vitro cell culture studies to examine the effects of E1 inhibition on cell growth and death\\n* In vivo mouse model study to evaluate the efficacy and toxicity of PYZD-4409 in treating leukemia.', 'models': 'The models or frameworks discussed in this text are:\\n\\n* Proteasomal pathway of protein degradation\\n* ER stress (Endoplasmic Reticulum stress)\\n\\nNote that there is no specific framework mentioned in the text, but rather a description of the proteasomal pathway and its relationship to ER stress.', 'funding': 'The text mentions funding sources/sponsors in the following sentence:\\n\\n\"...Thus, our work highlights the E1 enzyme as a novel target for the treatment of hematologic malignancies. 2010 by The American Society of Hematology.\"\\n\\nSo, the answer is: The American Society of Hematology (ASAH).'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': \"Based on the provided text, I found the following affiliations:\\n\\n* N/A (no explicit information about author or character affiliations is mentioned in the text)\\n\\nHowever, it's worth noting that the authors of the paper are likely affiliated with various institutions and organizations, but this information is not explicitly stated in the provided text. If you need more detailed information about the authors' affiliations, I recommend checking the original publication or searching for the paper's metadata.\", 'new_materials': 'The text mentions \"new recombinant antibodies\" which suggests the discovery of new materials. Therefore, I would answer:\\n\\nYes, the text mentions new materials or discoveries (specifically, new recombinant antibodies).', 'screening_algorithms': \"Yes, there are screening algorithms or systematic procedures discussed in the text. Specifically, the text describes a mass spectrometry-based standard operating procedure (SOP) for scoring immunoprecipitation antibody quality. The SOP involves quantifying the abundance of all proteins in immunoprecipitates and comparing normalized spectral abundance factors from the target antigen with those of all other proteins to classify antibodies as 'IP gold standard'.\", 'ai_algorithms': 'Based on the provided text, the answer is:\\n\\nYes, the text references the AI algorithm or method related to artificial intelligence in the following context: \"mass spectrometry-based standard operating procedure\". This indicates that the text utilizes mass spectrometry, which can be considered an AI-related method.', 'workflow': \"Based on the provided text, I can describe the workflow or process as follows:\\n\\n1. The process starts with immunoprecipitation (IP) of 1,124 new recombinant antibodies for 152 chromatin-related human proteins.\\n2. The resulting immunoprecipitates are analyzed by mass spectrometry to quantify the abundance of all proteins.\\n3. Normalized spectral abundance factors (NSAFs) are compared between the target antigen and all other proteins in each immunoprecipitate.\\n4. Antibodies for which the target antigen or a member of its known protein complex is the most abundant protein are classified as 'IP gold standard'.\\n5. The standard operating procedure (SOP) is validated through blinded studies in five independent laboratories.\\n\\nSo, the workflow involves using mass spectrometry to analyze immunoprecipitates and comparing NSAFs to assess antibody quality.\", 'methods': 'According to the provided text, the methods or approaches mentioned are:\\n\\n1. Mass spectrometry-based standard operating procedure for scoring immunoprecipitation antibody quality.\\n2. Quantifying the abundance of all proteins in immunoprecipitates by comparing normalized spectral abundance factors from the target antigen with those of all other proteins.\\n3. Validating the performance of the standard operating procedure in blinded studies in five independent laboratories.\\n\\nThese methods aim to assess and score antibody quality, which is crucial for maintaining data integrity and reproducibility in cell biology applications.', 'models': 'The models or frameworks discussed or used in this text are:\\n\\n* Mass spectrometry\\n* Standard operating procedure (SOP)\\n* Normalized spectral abundance factors (NSAF)\\n\\nThese methods are used to assess antibody quality and quantify protein abundance in immunoprecipitates.', 'funding': 'Based on the provided text, I found no mention of funding sources or sponsors. Therefore, my response is:\\n\\nN/A'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors of the study (not specified individually) have an affiliation with \"The American Society for Biochemistry and Molecular Biology, Inc.\".\\n\\nNote that there is no mention of any specific characters or individuals having affiliations. If you\\'re looking for information about the authors\\' institutions or departments, it\\'s not provided in this text.', 'new_materials': 'According to the provided text, there is no mention of new materials or discoveries. Therefore, the answer is:\\n\\nN/A', 'screening_algorithms': 'Based on the provided text, I found that there are no specific screening algorithms or systematic procedures discussed in the text. Therefore, my answer is:\\n\\nN/A', 'ai_algorithms': 'The text does not reference any AI algorithms or methods related to artificial intelligence. Therefore, the answer is N/A.', 'workflow': 'Based on the provided text, I can describe the workflow or process followed:\\n\\n1. Identification of a novel USP7-interacting protein (UbE2E1) through in vitro and in vivo experiments.\\n2. Characterization of the interaction between USP7 and UbE2E1 using biochemistry techniques (e.g., binding assays).\\n3. Investigation of the effect of USP7 on UbE2E1-mediated ubiquitination, including the requirement for specific sequences (ASTS) and catalytic activity.\\n4. Analysis of the role of USP7 in maintaining steady-state levels of UbE2E1 in cells.\\n\\nOverall, the study aimed to uncover a new mechanism involving the opposing activities of ubiquitination and deubiquitination enzymes to regulate the ubiquitin-proteasome system.', 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* In vitro and in vivo studies to show that USP7 forms a complex with UbE2E1\\n* Identification of the ASTSUSP7 binding motif within the N-terminal extension of UbE2E1 as necessary for the interaction with USP7\\n* Assay of USP7-mediated attenuation of UbE2E1-mediated ubiquitination, which requires both the N-terminal ASTS sequence of UbE2E1 and the catalytic activity of USP7\\n* Study of the role of USP7 in maintaining steady-state levels of UbE2E1 in cells\\n\\nSo, the answer is: These are the methods or approaches mentioned in the text.', 'models': 'The models or frameworks discussed in this text are:\\n\\n* Ubiquitin-proteasome system\\n* E2 ubiquitin conjugation enzyme (UbE2E1)\\n* ASTSUSP7 binding motif\\n\\nThese models and frameworks are relevant to the study of ubiquitination, a process that plays a crucial role in many cellular pathways.', 'funding': 'The text mentions that it is published \"2013 by The American Society for Biochemistry and Molecular Biology, Inc.\" which implies that the funding source or sponsor is The American Society for Biochemistry and Molecular Biology, Inc.'}\n",
      "affiliation What affiliations do the authors or characters in the text have?\n",
      "new_materials Does the text mention any new materials or discoveries?\n",
      "screening_algorithms Are there any screening algorithms or systematic procedures discussed in the text?\n",
      "ai_algorithms Does the text reference any AI algorithms or methods related to artificial intelligence?\n",
      "workflow Can you describe the workflow or process followed in the text?\n",
      "methods Can you summarize the methods or approaches mentioned in the text?\n",
      "models What models or frameworks are discussed or used in the text?\n",
      "funding Does the text mention any funding sources or sponsors?\n",
      "{'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* Authors:\\n\\t+ N/A (no specific authors or affiliations mentioned)\\n* Characters/Proteins:\\n\\t+ USP7/HAUSP: key regulator of p53 and Mdm2\\n\\t+ EBNA1: protein of Epstein-Barr virus (EBV)\\n\\t+ p53: tumor suppressor protein\\n\\t+ Mdm2: oncoprotein\\n\\nNote that there is no information about the affiliations of the authors or characters in this text.', 'new_materials': 'According to the text, there is no mention of new materials or discoveries. The text primarily discusses the crystal structure and binding properties of USP7/HAUSP with EBNA1 and p53 proteins, but does not introduce any novel materials or findings that would fit this category.\\n\\nOutput: N/A', 'screening_algorithms': 'Based on the provided text, I found that there is no specific mention of screening algorithms or systematic procedures discussed in the text. Therefore, my answer would be:\\n\\nN/A', 'ai_algorithms': 'N/A', 'workflow': 'The workflow or process described in this text can be summarized as follows:\\n\\n1. Determination of the crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide.\\n2. NMR chemical shift analyses of USP7 bound by EBNA1 and p53 to understand the binding modes and interactions between these proteins.\\n3. Functional studies to investigate how EBNA1 binding to USP7 affects p53 levels and cell survival in response to apoptotic challenge.\\n\\nIn summary, this text describes a research study that employed structural biology (crystallography) and biophysical techniques (NMR spectroscopy) to understand the interactions between USP7, p53, and EBNA1, and then used functional assays to investigate the consequences of these interactions on cellular survival.', 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* Determining the crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide\\n* NMR chemical shift analyses of USP7 bound by EBNA1 and p53\\n* Functional studies (no specific details provided)\\n\\nLet me know if you have any further questions or need assistance with anything else!', 'models': 'Based on the provided text, the following models or frameworks are discussed or used:\\n\\n* The crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide\\n* NMR chemical shift analyses of USP7 bound by EBNA1 and p53\\n* TRAF-C domains of TNF-receptor associated factors (mentioned as a comparison)\\n\\nSo, the output is:', 'funding': 'The answer is: N/A'}\n",
      "{'10.1038/s41586-020-2746-2': {'abstract': 'The genetic circuits that allow cancer cells to evade destruction by the host immune system remain poorly understood13. Here, to identify a phenotypically robust core set of genes and pathways that enable cancer cells to evade killing mediated by cytotoxic Tlymphocytes (CTLs), we performed genome-wide CRISPR screens across a panel of genetically diverse mouse cancer cell lines that were cultured in the presence of CTLs. We identify a core set of 182genes across these mouse cancer models, the individual perturbation of which increases either the sensitivity or the resistance of cancer cells to CTL-mediated toxicity. Systematic exploration of our dataset using genetic co-similarity reveals the hierarchical and coordinated manner in which genes and pathways act in cancer cells to orchestrate their evasion of CTLs, and shows that discrete functional modules that control the interferon response and tumour necrosis factor (TNF)-induced cytotoxicity are dominant sub-phenotypes. Our data establish a central role for genes that were previously identified as negative regulators of the type-II interferon response (for example, Ptpn2, Socs1 and Adar1) in mediating CTL evasion, and show that the lipid-droplet-related gene Fitm2 is required for maintaining cell fitness after exposure to interferon-? (IFN?). In addition, we identify the autophagy pathway as a conserved mediator of the evasion of CTLs by cancer cells, and show that this pathway is required to resist cytotoxicity induced by the cytokines IFN? andTNF. Through the mapping of cytokine- and CTL-based genetic interactions, together with in vivo CRISPR screens, we show how the pleiotropic effects of autophagy control cancer-cell-intrinsic evasion of killing by CTLs and we highlight the importance of these effects within the tumour microenvironment. Collectively, thesedata expand our knowledge of the genetic circuits that are involved in the evasion of the immune system by cancer cells, and highlight genetic interactions that contribute to phenotypes associated with escape from killing by CTLs.', 'topic': {'MACHINE LEARNING': ['CRISPR screens', 'genome-wide CRISPR screens', 'systematic exploration'], 'AI': ['genetic co-similarity'], 'Batteries': [], 'Accelerated Materials Discovery': [], 'Self Driving Labs': [], 'Autonomous Labs': [], 'High-Throughput Experimentation': ['high-throughput CRISPR screens'], 'High-Throughput DFT': []}, 'affiliation': 'Based on the provided text, here is the information you requested:\\n\\nThe authors of the text are not explicitly mentioned. However, the characters in the text can be categorized as follows:\\n\\n* Cancer cells\\n* Cytotoxic T-lymphocytes (CTLs)\\n* Mouse cancer cell lines\\n* Genes and pathways involved in cancer evasion (e.g., Ptpn2, Socs1, Adar1, Fitm2, autophagy pathway)\\n\\nPlease note that these are not affiliations in the classical sense but rather entities mentioned in the text.', 'new_materials': 'The text mentions several new discoveries:\\n\\n* The identification of a core set of 182 genes across mouse cancer models that enable cancer cells to evade killing mediated by cytotoxic T-lymphocytes (CTLs)\\n* The establishment of a central role for previously identified negative regulators of the type-II interferon response in mediating CTL evasion\\n* The discovery of Fitm2, a lipid-droplet-related gene required for maintaining cell fitness after exposure to interferon-?\\n* The identification of the autophagy pathway as a conserved mediator of the evasion of CTLs by cancer cells\\n\\nThese findings expand our knowledge of the genetic circuits involved in the evasion of the immune system by cancer cells.', 'screening_algorithms': 'Yes, there is screening algorithm or systematic procedure discussed in the text. The authors performed genome-wide CRISPR screens across a panel of genetically diverse mouse cancer cell lines to identify a core set of genes and pathways that enable cancer cells to evade killing mediated by cytotoxic T-lymphocytes (CTLs). Additionally, they used systematic exploration of their dataset using genetic co-similarity to reveal the hierarchical and coordinated manner in which genes and pathways act in cancer cells to orchestrate their evasion of CTLs.', 'ai_algorithms': 'The text does not reference any AI algorithms or methods related to artificial intelligence. Therefore, my answer is N/A.', 'workflow': 'The workflow or process followed in this text can be summarized as follows:\\n\\n1. Genome-wide CRISPR screens were performed across a panel of genetically diverse mouse cancer cell lines that were cultured in the presence of cytotoxic T lymphocytes (CTLs).\\n2. The screens aimed to identify a core set of genes and pathways that enable cancer cells to evade killing mediated by CTLs.\\n3. The data from the screens was analyzed to identify individual perturbations that increase either the sensitivity or resistance of cancer cells to CTL-mediated toxicity.\\n4. Systematic exploration of the dataset using genetic co-similarity revealed the hierarchical and coordinated manner in which genes and pathways act in cancer cells to orchestrate their evasion of CTLs.\\n5. The data was used to establish a central role for certain genes in mediating CTL evasion, identify autophagy as a conserved mediator of evasion, and show how autophagy controls cancer-cell-intrinsic evasion of killing by CTLs.\\n6. In vivo CRISPR screens were performed to map cytokine- and CTL-based genetic interactions.\\n\\nOverall, the workflow involved using CRISPR screens to identify genes and pathways that enable cancer cells to evade the immune system, followed by analysis and interpretation of the data to understand the underlying mechanisms.', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n1. Genome-wide CRISPR screens\\n2. Systematic exploration of dataset using genetic co-similarity\\n3. Mapping of cytokine- and CTL-based genetic interactions\\n4. In vivo CRISPR screens\\n\\nThese methods were used to identify a core set of genes and pathways that enable cancer cells to evade killing mediated by cytotoxic T lymphocytes (CTLs).', 'models': \"The models or frameworks discussed or used in this text are:\\n\\n* CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) screens\\n* Genetic co-similarity framework\\n* Autophagy pathway model\\n* Type-II interferon response model\\n* TNF-induced cytotoxicity model\\n\\nSo, the answer is not 'N/A'!\", 'funding': 'N/A'}, '10.1186/s12885-016-2539-z': {'abstract': 'Background: Patients with clear cell renal cell carcinoma (ccRCC) have few therapeutic options, as ccRCC is unresponsive to chemotherapy and is highly resistant to radiation. Recently targeted therapies have extended progression-free survival, but responses are variable and no significant overall survival benefit has been achieved. Commercial ccRCC cell lines are often used as model systems to develop novel therapeutic approaches, but these do not accurately recapitulate primary ccRCC tumors at the genomic and transcriptional levels. Furthermore, ccRCC exhibits significant intertumor genetic heterogeneity, and the limited cell lines available fail to represent this aspect of ccRCC. Our objective was to generate accurate preclinical in vitro models of ccRCC using tumor tissues from ccRCC patients. Methods: ccRCC primary single cell suspensions were cultured in fetal bovine serum (FBS)-containing media or defined serum-free media. Established cultures were characterized by genomic verification of mutations present in the primary tumors, expression of renal epithelial markers, and transcriptional profiling. Results: The apparent efficiency of primary cell culture establishment was high in both culture conditions, but genotyping revealed that the majority of cultures contained normal, not cancer cells. ccRCC characteristically shows biallelic loss of the von Hippel Lindau (VHL) gene, leading to accumulation of hypoxia-inducible factor (HIF) and expression of HIF target genes. Purification of cells based on expression of carbonic anhydrase IX (CA9), a cell surface HIF target, followed by culture in FBS enabled establishment of ccRCC cell cultures with an efficiency of >80 %. Culture in serum-free conditions selected for growth of normal renal proximal tubule epithelial cells. Transcriptional profiling of ccRCC and matched normal cell cultures identified up- and down-regulated networks in ccRCC and comparison to The Cancer Genome Atlas confirmed the clinical validity of our cell cultures. Conclusions: The ability to establish primary cultures of ccRCC cells and matched normal kidney epithelial cells from almost every patient provides a resource for future development of novel therapies and personalized medicine for ccRCC patients.', 'topic': {'MACHINE LEARNING': [], 'BATTERIES': [], 'AI': [], 'ACCELERATED MATERIALS DISCOVERY': [], 'SELF DRIVING LABS': [], 'AUTONOMOUS LABS': [], 'HIGH-THROUGHPUT EXPERIMENTATION': ['high-throughput experimentation'], 'HIGH-THROUGHPUT DFT': []}, 'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors do not have any affiliations explicitly stated in this text. However, it is common practice for researchers to include their affiliations (e.g., institutions, universities, research centers) at the end of an article or paper.\\n* The characters (in this case, patients with clear cell renal cell carcinoma and normal kidney epithelial cells) do not have any affiliations mentioned in this text.', 'new_materials': 'The text mentions new materials or discoveries in the following points:\\n\\n* The ability to establish primary cultures of ccRCC cells with an efficiency of >80% using purification of cells based on expression of carbonic anhydrase IX (CA9) and culture in FBS.\\n* The development of a resource for future development of novel therapies and personalized medicine for ccRCC patients.\\n\\nSo, the answer is: Yes, the text mentions new materials or discoveries.', 'screening_algorithms': 'After reviewing the provided text, I found that there are no specific screening algorithms or systematic procedures discussed. The text primarily focuses on the methodology used to establish primary cell cultures of clear cell renal cell carcinoma (ccRCC) and matched normal kidney epithelial cells.\\n\\nSo, the answer is: N/A', 'ai_algorithms': 'Based on the provided text, I did not find any direct references to AI algorithms or methods related to artificial intelligence. Therefore, my answer is:\\n\\nN/A', 'workflow': 'Based on the provided text, the workflow or process followed is:\\n\\n1. Generation of primary single cell suspensions from clear cell renal cell carcinoma (ccRCC) tumor tissues.\\n2. Culture of these suspensions in fetal bovine serum (FBS)-containing media or defined serum-free media.\\n3. Characterization of established cultures by:\\n\\t* Genomic verification of mutations present in the primary tumors.\\n\\t* Expression of renal epithelial markers.\\n\\t* Transcriptional profiling.\\n4. Purification of cells based on expression of carbonic anhydrase IX (CA9), a cell surface hypoxia-inducible factor (HIF) target, to establish ccRCC cell cultures with high efficiency (>80%).\\n5. Culture in serum-free conditions to select for growth of normal renal proximal tubule epithelial cells.\\n6. Transcriptional profiling of ccRCC and matched normal cell cultures to identify up- and down-regulated networks in ccRCC and compare to The Cancer Genome Atlas (TCGA) data.\\n\\nPlease note that this process is specific to the establishment of primary cultures of ccRCC cells from patient tumor tissues, and may not be applicable to other research topics or areas.', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n1. Primary cell suspension culture using fetal bovine serum (FBS)-containing media or defined serum-free media.\\n2. Genomic verification of mutations present in primary tumors to characterize established cultures.\\n3. Expression of renal epithelial markers to confirm the identity of cultured cells.\\n4. Transcriptional profiling to analyze gene expression patterns in ccRCC and matched normal cell cultures.\\n5. Purification of cells based on expression of carbonic anhydrase IX (CA9), a cell surface HIF target, to establish ccRCC cell cultures.\\n\\nThese methods were used to generate accurate preclinical in vitro models of clear cell renal cell carcinoma (ccRCC) using tumor tissues from patients with ccRCC.', 'models': 'The models or frameworks discussed in this text are:\\n\\n* The Cancer Genome Atlas (TCGA)\\n\\nAdditionally, the text mentions several biological pathways and processes, including:\\n\\n* Hypoxia-inducible factor (HIF) pathway\\n* Von Hippel Lindau (VHL) gene regulation\\n* Carbonic anhydrase IX (CA9) as a cell surface marker for ccRCC cells\\n\\nHowever, there are no specific statistical or analytical frameworks mentioned in the text.', 'funding': 'N/A'}, '10.1038/nmeth.2895': {'abstract': 'Cell signaling, one of key processes in both normal cellular function and disease, is coordinated by numerous interactions between membrane proteins that change in response to stimuli. We present a split ubiquitin-based method for detection of integral membrane protein-protein interactions (PPIs) in human cells, termed mammalian-membrane two-hybrid assay (MaMTH). We show that this technology detects stimulus (hormone or agonist)-dependent and phosphorylation-dependent PPIs. MaMTH can detect changes in PPIs conferred by mutations such as those in oncogenic ErbB receptor variants or by treatment with drugs such as the tyrosine kinase inhibitor erlotinib. Using MaMTH as a screening assay, we identified CRKII as an interactor of oncogenic EGFR(L858R) and showed that CRKII promotes persistent activation of aberrant signaling in non-small cell lung cancer cells. MaMTH is a powerful tool for investigating the dynamic interactomes of human integral membrane proteins.  2014 Nature America, Inc.', 'topic': {'MACHINE LEARNING': [], 'AI': ['Machine Learning'], 'accelerated materials discovery': [], 'Batteries': []}, 'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors/characters in the text do not have explicit affiliations mentioned. However, it is noted that the study was published in Nature America, Inc., which suggests an affiliation with the journal.\\n\\nOutput: N/A (since there are no explicit author or character affiliations mentioned)', 'new_materials': 'According to the provided text, there are no new materials or discoveries mentioned. The text discusses a method for detecting interactions between membrane proteins (MaMTH) and its applications in understanding cellular signaling processes, but it does not introduce any novel materials or discoveries. Therefore, the answer is: N/A.', 'screening_algorithms': 'According to the provided text, yes, there are screening algorithms or systematic procedures discussed. Specifically, the text mentions a \"split ubiquitin-based method\" called MaMTH (mammalian-membrane two-hybrid assay) that can be used as a screening assay for detecting protein-protein interactions and changes in these interactions conferred by mutations or treatments.', 'ai_algorithms': 'The answer is: N/A\\n\\nThere are no references to AI algorithms or methods related to artificial intelligence in this text. The text discusses a biological method for detecting protein-protein interactions called MaMTH (mammalian-membrane two-hybrid assay) and its application in studying cell signaling pathways.', 'workflow': 'Based on the provided text, I can describe the workflow or process followed as:\\n\\n1. Detection of integral membrane protein-protein interactions (PPIs) using a split ubiquitin-based method called mammalian-membrane two-hybrid assay (MaMTH).\\n2. MaMTH detects stimulus-dependent and phosphorylation-dependent PPIs in human cells.\\n3. The technology can detect changes in PPIs conferred by:\\n\\t* Mutations, such as those in oncogenic ErbB receptor variants\\n\\t* Treatment with drugs, such as the tyrosine kinase inhibitor erlotinib\\n4. MaMTH is used as a screening assay to identify interactors of specific proteins or to investigate dynamic interactomes of human integral membrane proteins.\\n\\nLet me know if you have any further questions!', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n* Split ubiquitin-based method\\n* Mammalian-membrane two-hybrid assay (MaMTH)\\n* Screening assay using MaMTH as a tool for investigating the dynamic interactomes of human integral membrane proteins.\\n\\nLet me know if you need any further assistance!', 'models': 'The models or frameworks discussed in this text are:\\n\\n* Split ubiquitin-based method\\n* Mammalian-membrane two-hybrid assay (MaMTH)\\n\\nThese models or frameworks are used to detect and study protein-protein interactions (PPIs) in human cells.', 'funding': 'The text does not mention any specific funding sources or sponsors. Therefore, my answer is: N/A'}, '10.1016/j.celrep.2012.09.016': {'abstract': 'The pentaspan membrane glycoprotein CD133 marks lineage-specific cancer progenitor cells and is associated with poor prognosis in a number of tumor types. Despite its utility as a cancer progenitor cell marker, CD133 protein regulation and molecular function remain poorly understood. We find that the deacetylase HDAC6 physically associates with CD133 to negatively regulate CD133 trafficking down the endosomal-lysosomal pathway for degradation. We further demonstrate that CD133, HDAC6, and the central molecule of the canonical Wnt signaling pathway, ?-catenin, can physically associate as a ternary complex. This association stabilizes ?-catenin via HDAC6 deacetylase activity, which leads to activation of ?-catenin signaling targets. Downregulation of either CD133 or HDAC6 results in increased ?-catenin acetylation and degradation, which correlates with decreased proliferation in vitro and tumor xenograft growth in vivo. Given that CD133 marks progenitor cells in a wide range of cancers, targeting CD133 may be a means to treat multiple cancer types', 'topic': {'Molecular Biology': ['CD133', 'HDAC6', 'Wnt signaling pathway', 'acetylation', 'degradation'], 'No Topic Found': []}, 'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* Authors:\\n\\t+ N/A (no specific authors or affiliations mentioned)\\n* Characters/Proteins:\\n\\t+ CD133: a membrane glycoprotein\\n\\t+ HDAC6: deacetylase protein\\n\\t+ ?-catenin: central molecule of the canonical Wnt signaling pathway\\n\\nLet me know if you have any further questions!', 'new_materials': 'According to the text, there is no mention of new materials or discoveries. Therefore, my answer would be:\\n\\nN/A', 'screening_algorithms': 'Yes, there are screening algorithms or systematic procedures discussed in the text.\\n\\nSpecifically, the text mentions:\\n\\n* The physical association of HDAC6 with CD133 and ?-catenin\\n* The regulation of CD133 trafficking down the endosomal-lysosomal pathway for degradation by HDAC6\\n* The stabilization of ?-catenin via HDAC6 deacetylase activity leading to activation of ?-catenin signaling targets\\n* The correlation between CD133/HDAC6 downregulation and increased ?-catenin acetylation and degradation, which affects proliferation in vitro and tumor xenograft growth in vivo.\\n\\nThese findings suggest a systematic procedure for understanding the molecular function and regulation of CD133, as well as its potential role in cancer development and treatment.', 'ai_algorithms': 'Based on the provided text, I found no reference to AI algorithms or methods related to artificial intelligence. Therefore, my answer is:\\n\\nN/A', 'workflow': \"Based on the provided text, I can describe the workflow or process as follows:\\n\\n1. Introduction: The text introduces the protein CD133 and its role in marking lineage-specific cancer progenitor cells.\\n2. Research question: The authors investigate the regulation of CD133 protein and its molecular function.\\n3. Findings:\\n\\t* The deacetylase HDAC6 physically associates with CD133 to negatively regulate CD133 trafficking down the endosomal-lysosomal pathway for degradation.\\n\\t* CD133, HDAC6, and ?-catenin (a central molecule in the canonical Wnt signaling pathway) can physically associate as a ternary complex.\\n\\t* This association stabilizes ?-catenin via HDAC6 deacetylase activity, leading to activation of ?-catenin signaling targets.\\n4. Consequences:\\n\\t* Downregulation of either CD133 or HDAC6 results in increased ?-catenin acetylation and degradation.\\n\\t* Decreased proliferation is observed in vitro and tumor xenograft growth in vivo.\\n5. Conclusion: The study suggests that targeting CD133 may be a means to treat multiple cancer types.\\n\\nPlease let me know if you have any further questions or if there's anything else I can assist you with!\", 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* Physical association studies to identify interactions between proteins (CD133, HDAC6, and ?-catenin)\\n* Cellular assays (in vitro) to study the effects of CD133 and HDAC6 regulation on ?-catenin signaling targets\\n* Xenograft growth experiments (in vivo) to evaluate the impact of CD133 and HDAC6 downregulation on tumor growth\\n\\nThese methods were used to investigate the molecular function and regulation of CD133, as well as its potential role in cancer development and treatment.', 'models': 'The models or frameworks discussed or used in this text are:\\n\\n* Canonical Wnt signaling pathway\\n* Endosomal-lysosomal pathway for degradation\\n\\nSo, the answer is not \"N/A\"!', 'funding': 'N/A'}, '10.1158/1535-7163.MCT-09-0495': {'abstract': 'Evasion of death receptor ligand-induced apoptosis represents an important contributor to cancer development and progression. Therefore, molecules that restore sensitivity to death receptor stimuli would be important tools to better understand this biological pathway and potential leads for therapeutic adjuncts. Previously, the small-molecule 4-(4-chloro-2-methylphenoxy)-N- hydroxybutanamide (that we propose be named droxinostat) was identified as a chemical sensitizer to death receptor stimuli, decreasing the expression of the caspase-8 inhibitor FLIP. However, the direct targets of droxinostat were unknown. To better understand the mechanism of action of droxinostat and highlight new strategies to restore sensitivity to death receptor ligands, we analyzed changes in gene expression using the Connectivity Map after treating cells with droxinostat. Changes in gene expression after droxinostat treatment resembled changes observed after treatment with histone deacetylase (HDAC) inhibitors. Therefore, we examined the effects of droxinostat on HDAC activity and showed that it selectively inhibited HDAC3, HDAC6, and HDAC8 and that inhibition of these HDACs was functionally important for its ability to sensitize cells to death ligands. Thus, we have identified a selective HDAC inhibitor and showed that selective HDAC inhibition sensitizes cells to death ligands, thereby highlighting a new mechanism to overcome resistance to death receptor ligands. 2010 AACR.', 'topic': {'MACHINE LEARNING': [], 'AI': ['Connectivity Map'], 'Batteries': [], 'accelerated materials discovery': [], 'Self Driving Labs': [], 'autonomous labs': [], 'high-throughput experimentation': [], 'high-throughput DFT': []}, 'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors of the study are not explicitly stated in the text.\\n* The AACR (American Association for Cancer Research) is mentioned as the publisher of the study, but no specific affiliation is given.\\n\\nSo, the output would be:\\n\\nN/A', 'new_materials': 'According to the provided text, YES, it mentions new materials or discoveries. Specifically:\\n\\n* A small-molecule compound called droxinostat (4-(4-chloro-2-methylphenoxy)-N-hydroxybutanamide) was identified as a chemical sensitizer to death receptor stimuli.\\n* The mechanism of action of droxinostat was found to involve the selective inhibition of HDAC3, HDAC6, and HDAC8 enzymes.\\n\\nSo, there are new materials (droxinostat) and discoveries (mechanism of action) mentioned in the text.', 'screening_algorithms': 'According to the text, yes, there are screening algorithms or systematic procedures discussed. Specifically, the authors mention using the Connectivity Map to analyze changes in gene expression after treating cells with droxinostat. Additionally, they discuss the effects of droxinostat on HDAC activity and examine the functional importance of inhibiting specific HDACs for its ability to sensitize cells to death ligands.', 'ai_algorithms': \"The text references AI algorithms or methods related to artificial intelligence.\\n\\nSpecifically, it mentions the use of the Connectivity Map, which is a computational tool that uses gene expression data to identify patterns and relationships between different biological pathways. This suggests that the authors used some form of bioinformatics analysis to analyze changes in gene expression after treating cells with droxinostat.\\n\\nTherefore, I would output: 'Yes'\", 'workflow': \"The workflow or process followed in this text can be described as follows:\\n\\n1. Identification of a molecule (droxinostat) that restores sensitivity to death receptor stimuli and decreases expression of FLIP.\\n2. Analysis of changes in gene expression using the Connectivity Map after treating cells with droxinostat.\\n3. Comparison of results from step 2 with changes observed after treatment with histone deacetylase (HDAC) inhibitors, leading to a hypothesis about the mechanism of action of droxinostat.\\n4. Examination of the effects of droxinostat on HDAC activity and identification of specific HDACs (HDAC3, HDAC6, and HDAC8) that are inhibited by droxinostat.\\n5. Functional analysis of the importance of inhibiting these HDACs for droxinostat's ability to sensitize cells to death ligands.\\n\\nOverall, the process involves a combination of molecular biology techniques, including gene expression analysis and enzyme activity assays, as well as functional studies to understand the mechanism of action of a small molecule (droxinostat).\", 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* Analyzing changes in gene expression using the Connectivity Map after treating cells with droxinostat\\n* Examining the effects of droxinostat on HDAC activity\\n* Inhibiting specific HDACs (HDAC3, HDAC6, and HDAC8) to study their functional importance in sensitizing cells to death ligands\\n\\nLet me know if you have any further questions!', 'models': 'The models or frameworks discussed in this text are:\\n\\n* The Connectivity Map\\n* Histone deacetylase (HDAC) inhibitors\\n\\nThese frameworks are used to analyze changes in gene expression and understand the mechanism of action of droxinostat.', 'funding': 'The text does not mention any specific funding sources or sponsors. Therefore, my answer is \"N/A\".'}, '10.1182/blood-2009-07-231191': {'abstract': 'The proteasomal pathway of protein degradation involves 2 discrete steps: ubiquitination and degradation. Here, we evaluated the effects of inhibiting the ubiquitination pathway at the level of the ubiquitin-activating enzyme UBA1 (E1). By immunoblotting, leukemia cell lines and primary patient samples had increased protein ubiquitination. Therefore, we examined the effects of genetic and chemical inhibition of the E1 enzyme. Knockdown of E1 decreased the abundance of ubiquitinated proteins in leukemia and myeloma cells and induced cell death. To further investigate effects of E1 inhibition in malignancy, we discovered a novel small molecule inhibitor, 3,5-dioxopyrazolidine compound, 1-(3-chloro-4-fluorophenyl)-4-[(5-nitro-2-furyl)methylene]-3, 5-pyrazolidinedione (PYZD-4409). PYZD-4409 induced cell death in malignant cells and preferentially inhibited the clonogenic growth of primary acute myeloid leukemia cells compared with normal hematopoietic cells. Mechanistically, genetic or chemical inhibition of E1 increased expression of E1 stress markers. Moreover, BI-1 overexpression blocked cell death after E1 inhibition, suggesting ER stress is functionally important for cell death after E1 inhibition. Finally, in a mouse model of leukemia, intraperitoneal administration of PYZD-4409 decreased tumor weight and volume compared with control without untoward toxicity. Thus, our work highlights the E1 enzyme as a novel target for the treatment of hematologic malignancies.  2010 by The American Society of Hematology.', 'topic': {'MACHINE LEARNING': [], 'BATTERIES': [], 'AI': [], 'ACCELERATED MATERIALS DISCOVERY': ['high-throughput experimentation'], 'SELF DRIVING LABS': [], 'AUTONOMOUS LABS': [], 'HIGH-THROUGHPUT DFT': []}, 'affiliation': 'The authors or characters in this text have the following affiliations:\\n\\n* Authors: N/A (the text does not mention specific authors or their affiliations)\\n* Characters: None (this is a scientific article and does not involve fictional characters)\\n\\nHowever, the text mentions the American Society of Hematology as the copyright holder.', 'new_materials': 'The text mentions a novel small molecule inhibitor called PYZD-4409, which is a 3,5-dioxopyrazolidine compound. Therefore, the answer is:\\n\\nYES', 'screening_algorithms': 'Yes, there are screening algorithms or systematic procedures discussed in the text.\\n\\nThe text mentions several systematic procedures:\\n\\n1. Immunoblotting to evaluate protein ubiquitination.\\n2. Knockdown of E1 enzyme to examine its effects on ubiquitinated proteins and cell death.\\n3. Inhibition of E1 enzyme using a small molecule inhibitor (PYZD-4409) to investigate its effects on malignant cells and normal hematopoietic cells.\\n4. Overexpression of BI-1 to block cell death after E1 inhibition.\\n\\nThese procedures are used to systematically evaluate the effects of inhibiting the ubiquitination pathway at the level of the ubiquitin-activating enzyme UBA1 (E1) in leukemia and myeloma cells, as well as in a mouse model of leukemia.', 'ai_algorithms': 'The text does not reference any AI algorithms or methods related to artificial intelligence. Therefore, the answer is N/A.', 'workflow': 'Based on the provided text, the workflow or process followed can be described as follows:\\n\\n1. Introduction to the proteasomal pathway of protein degradation and its two discrete steps: ubiquitination and degradation.\\n2. Evaluation of the effects of inhibiting the ubiquitin-activating enzyme UBA1 (E1) at the level of E1.\\n3. Immunoblotting analysis to examine the levels of ubiquitinated proteins in leukemia cell lines and primary patient samples, revealing increased protein ubiquitination.\\n4. Genetic and chemical inhibition of the E1 enzyme:\\n\\t* Knockdown of E1 decreased the abundance of ubiquitinated proteins in leukemia and myeloma cells and induced cell death.\\n5. Discovery of a novel small molecule inhibitor, PYZD-4409, which:\\n\\t* Induced cell death in malignant cells\\n\\t* Preferentially inhibited the clonogenic growth of primary acute myeloid leukemia cells compared with normal hematopoietic cells\\n6. Mechanistic studies:\\n\\t* Genetic or chemical inhibition of E1 increased expression of E1 stress markers\\n\\t* Overexpression of BI-1 blocked cell death after E1 inhibition, suggesting ER stress is functionally important for cell death after E1 inhibition\\n7. In vivo study:\\n\\t* Intraperitoneal administration of PYZD-4409 decreased tumor weight and volume in a mouse model of leukemia without untoward toxicity\\n\\nOverall, the text describes the discovery of a novel target (E1 enzyme) and its potential as a therapeutic approach for treating hematologic malignancies.', 'methods': 'The methods or approaches mentioned in the text are:\\n\\n* Immunoblotting\\n* Genetic inhibition (knockdown) of the ubiquitin-activating enzyme UBA1 (E1)\\n* Chemical inhibition using a small molecule inhibitor, 3,5-dioxopyrazolidine compound, 1-(3-chloro-4-fluorophenyl)-4-[(5-nitro-2-furyl)methylene]-3, 5-pyrazolidinedione (PYZD-4409)\\n* Overexpression of BI-1\\n* In vitro cell culture studies to examine the effects of E1 inhibition on cell growth and death\\n* In vivo mouse model study to evaluate the efficacy and toxicity of PYZD-4409 in treating leukemia.', 'models': 'The models or frameworks discussed in this text are:\\n\\n* Proteasomal pathway of protein degradation\\n* ER stress (Endoplasmic Reticulum stress)\\n\\nNote that there is no specific framework mentioned in the text, but rather a description of the proteasomal pathway and its relationship to ER stress.', 'funding': 'The text mentions funding sources/sponsors in the following sentence:\\n\\n\"...Thus, our work highlights the E1 enzyme as a novel target for the treatment of hematologic malignancies. 2010 by The American Society of Hematology.\"\\n\\nSo, the answer is: The American Society of Hematology (ASAH).'}, '10.1038/nmeth.3472': {'abstract': \"Antibodies are used in multiple cell biology applications, but there are no standardized methods to assess antibody quality - an absence that risks data integrity and reproducibility. We describe a mass spectrometry-based standard operating procedure for scoring immunoprecipitation antibody quality. We quantified the abundance of all the proteins in immunoprecipitates of 1,124 new recombinant antibodies for 152 chromatin-related human proteins by comparing normalized spectral abundance factors from the target antigen with those of all other proteins. We validated the performance of the standard operating procedure in blinded studies in five independent laboratories. Antibodies for which the target antigen or a member of its known protein complex was the most abundant protein were classified as 'IP gold standard'. This method generates quantitative outputs that can be stored and archived in public databases, and it represents a step toward a platform for community benchmarking of antibody quality.\", 'topic': {'MACHINE LEARNING': [], 'AI': ['mass spectrometry-based standard operating procedure', 'quantified'], 'BATTERIES': [], 'ACCELERATED MATERIALS DISCOVERY': [], 'SELF DRIVING LABS': [], 'AUTONOMOUS LABS': [], 'HIGH-THROUGHPUT EXPERIMENTATION': ['high-throughput'], 'HIGH-THROUGHPUT DFT': []}, 'affiliation': \"Based on the provided text, I found the following affiliations:\\n\\n* N/A (no explicit information about author or character affiliations is mentioned in the text)\\n\\nHowever, it's worth noting that the authors of the paper are likely affiliated with various institutions and organizations, but this information is not explicitly stated in the provided text. If you need more detailed information about the authors' affiliations, I recommend checking the original publication or searching for the paper's metadata.\", 'new_materials': 'The text mentions \"new recombinant antibodies\" which suggests the discovery of new materials. Therefore, I would answer:\\n\\nYes, the text mentions new materials or discoveries (specifically, new recombinant antibodies).', 'screening_algorithms': \"Yes, there are screening algorithms or systematic procedures discussed in the text. Specifically, the text describes a mass spectrometry-based standard operating procedure (SOP) for scoring immunoprecipitation antibody quality. The SOP involves quantifying the abundance of all proteins in immunoprecipitates and comparing normalized spectral abundance factors from the target antigen with those of all other proteins to classify antibodies as 'IP gold standard'.\", 'ai_algorithms': 'Based on the provided text, the answer is:\\n\\nYes, the text references the AI algorithm or method related to artificial intelligence in the following context: \"mass spectrometry-based standard operating procedure\". This indicates that the text utilizes mass spectrometry, which can be considered an AI-related method.', 'workflow': \"Based on the provided text, I can describe the workflow or process as follows:\\n\\n1. The process starts with immunoprecipitation (IP) of 1,124 new recombinant antibodies for 152 chromatin-related human proteins.\\n2. The resulting immunoprecipitates are analyzed by mass spectrometry to quantify the abundance of all proteins.\\n3. Normalized spectral abundance factors (NSAFs) are compared between the target antigen and all other proteins in each immunoprecipitate.\\n4. Antibodies for which the target antigen or a member of its known protein complex is the most abundant protein are classified as 'IP gold standard'.\\n5. The standard operating procedure (SOP) is validated through blinded studies in five independent laboratories.\\n\\nSo, the workflow involves using mass spectrometry to analyze immunoprecipitates and comparing NSAFs to assess antibody quality.\", 'methods': 'According to the provided text, the methods or approaches mentioned are:\\n\\n1. Mass spectrometry-based standard operating procedure for scoring immunoprecipitation antibody quality.\\n2. Quantifying the abundance of all proteins in immunoprecipitates by comparing normalized spectral abundance factors from the target antigen with those of all other proteins.\\n3. Validating the performance of the standard operating procedure in blinded studies in five independent laboratories.\\n\\nThese methods aim to assess and score antibody quality, which is crucial for maintaining data integrity and reproducibility in cell biology applications.', 'models': 'The models or frameworks discussed or used in this text are:\\n\\n* Mass spectrometry\\n* Standard operating procedure (SOP)\\n* Normalized spectral abundance factors (NSAF)\\n\\nThese methods are used to assess antibody quality and quantify protein abundance in immunoprecipitates.', 'funding': 'Based on the provided text, I found no mention of funding sources or sponsors. Therefore, my response is:\\n\\nN/A'}, '10.1074/jbc.M113.469262': {'abstract': 'Ubiquitin-specific protease 7 (USP7) is a deubiquitinating enzyme found in all eukaryotes that catalyzes the removal of ubiquitin from specific target proteins. Here, we report that UbE2E1, an E2 ubiquitin conjugation enzyme with a unique N-terminal extension, is a novel USP7-interacting protein. USP7 forms a complex with UbE2E1 in vitro and in vivo through theASTSUSP7 binding motif within its N-terminal extension in an identical manner with other known USP7 binding proteins. We show that USP7 attenuates UbE2E1-mediated ubiquitination, an effect that requires the N-terminal ASTS sequence of UbE2E1 as well as the catalytic activity of USP7. Additionally, USP7 is critical in maintaining the steady state levels of UbE2E1 in cells. This study reveals a new cellular mechanism that couples the opposing activities of the ubiquitination machinery and a deubiquitinating enzyme to maintain and modulate the dynamic balance of the ubiquitin-proteasome system.  2013 by The American Society for Biochemistry and Molecular Biology, Inc.', 'topic': {'Molecular Biology': ['Ubiquitin-specific protease 7', 'USP7', 'UbE2E1', 'ubiquitination'], 'Biochemistry': ['Ubiquitin-proteasome system', 'deubiquitinating enzyme', 'ubiquitination'], 'Machine Learning': [], 'Batteries': [], 'AI': [], 'accelerated materials discovery': [], 'Self Driving Labs': [], 'autonomous labs': [], 'high-throughput experimentation': [], 'high-throughput DFT': []}, 'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* The authors of the study (not specified individually) have an affiliation with \"The American Society for Biochemistry and Molecular Biology, Inc.\".\\n\\nNote that there is no mention of any specific characters or individuals having affiliations. If you\\'re looking for information about the authors\\' institutions or departments, it\\'s not provided in this text.', 'new_materials': 'According to the provided text, there is no mention of new materials or discoveries. Therefore, the answer is:\\n\\nN/A', 'screening_algorithms': 'Based on the provided text, I found that there are no specific screening algorithms or systematic procedures discussed in the text. Therefore, my answer is:\\n\\nN/A', 'ai_algorithms': 'The text does not reference any AI algorithms or methods related to artificial intelligence. Therefore, the answer is N/A.', 'workflow': 'Based on the provided text, I can describe the workflow or process followed:\\n\\n1. Identification of a novel USP7-interacting protein (UbE2E1) through in vitro and in vivo experiments.\\n2. Characterization of the interaction between USP7 and UbE2E1 using biochemistry techniques (e.g., binding assays).\\n3. Investigation of the effect of USP7 on UbE2E1-mediated ubiquitination, including the requirement for specific sequences (ASTS) and catalytic activity.\\n4. Analysis of the role of USP7 in maintaining steady-state levels of UbE2E1 in cells.\\n\\nOverall, the study aimed to uncover a new mechanism involving the opposing activities of ubiquitination and deubiquitination enzymes to regulate the ubiquitin-proteasome system.', 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* In vitro and in vivo studies to show that USP7 forms a complex with UbE2E1\\n* Identification of the ASTSUSP7 binding motif within the N-terminal extension of UbE2E1 as necessary for the interaction with USP7\\n* Assay of USP7-mediated attenuation of UbE2E1-mediated ubiquitination, which requires both the N-terminal ASTS sequence of UbE2E1 and the catalytic activity of USP7\\n* Study of the role of USP7 in maintaining steady-state levels of UbE2E1 in cells\\n\\nSo, the answer is: These are the methods or approaches mentioned in the text.', 'models': 'The models or frameworks discussed in this text are:\\n\\n* Ubiquitin-proteasome system\\n* E2 ubiquitin conjugation enzyme (UbE2E1)\\n* ASTSUSP7 binding motif\\n\\nThese models and frameworks are relevant to the study of ubiquitination, a process that plays a crucial role in many cellular pathways.', 'funding': 'The text mentions that it is published \"2013 by The American Society for Biochemistry and Molecular Biology, Inc.\" which implies that the funding source or sponsor is The American Society for Biochemistry and Molecular Biology, Inc.'}, '10.1016/j.molcel.2005.02.029': {'abstract': 'USP7/HAUSP is a key regulator of p53 and Mdm2 and is targeted by the Epstein-Barr nuclear antigen 1 (EBNA1) protein of Epstein-Barr virus (EBV). We have determined the crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide. This domain is an eight-stranded ? sandwich similar to the TRAF-C domains of TNF-receptor associated factors, although the mode of peptide binding differs significantly from previously observed TRAF-peptide interactions in the sequence (DPGEGPS) and the conformation of the bound peptide. NMR chemical shift analyses of USP7 bound by EBNA1 and p53 indicated that p53 binds the same pocket as EBNA1 but makes less extensive contacts with USP7. Functional studies indicated that EBNA1 binding to USP7 can protect cells from apoptotic challenge by lowering p53 levels. The data provide a structural and conceptual framework for understanding how EBNA1 might contribute to the survival of Epstein-Barr virus-infected cells. Copyright 2005 by Elsevier Inc.', 'topic': {'Molecular Biology': ['USP7', 'HAUSP', 'p53', 'Mdm2', 'Epstein-Barr virus', 'EBV'], 'Structural Biology': ['crystal structure', 'NMR chemical shift analyses'], 'Biotechnology': ['apoptotic challenge', 'functional studies'], 'Molecular Medicine': ['survival of Epstein-Barr virus-infected cells']}, 'affiliation': 'Based on the provided text, here are the affiliations mentioned:\\n\\n* Authors:\\n\\t+ N/A (no specific authors or affiliations mentioned)\\n* Characters/Proteins:\\n\\t+ USP7/HAUSP: key regulator of p53 and Mdm2\\n\\t+ EBNA1: protein of Epstein-Barr virus (EBV)\\n\\t+ p53: tumor suppressor protein\\n\\t+ Mdm2: oncoprotein\\n\\nNote that there is no information about the affiliations of the authors or characters in this text.', 'new_materials': 'According to the text, there is no mention of new materials or discoveries. The text primarily discusses the crystal structure and binding properties of USP7/HAUSP with EBNA1 and p53 proteins, but does not introduce any novel materials or findings that would fit this category.\\n\\nOutput: N/A', 'screening_algorithms': 'Based on the provided text, I found that there is no specific mention of screening algorithms or systematic procedures discussed in the text. Therefore, my answer would be:\\n\\nN/A', 'ai_algorithms': 'N/A', 'workflow': 'The workflow or process described in this text can be summarized as follows:\\n\\n1. Determination of the crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide.\\n2. NMR chemical shift analyses of USP7 bound by EBNA1 and p53 to understand the binding modes and interactions between these proteins.\\n3. Functional studies to investigate how EBNA1 binding to USP7 affects p53 levels and cell survival in response to apoptotic challenge.\\n\\nIn summary, this text describes a research study that employed structural biology (crystallography) and biophysical techniques (NMR spectroscopy) to understand the interactions between USP7, p53, and EBNA1, and then used functional assays to investigate the consequences of these interactions on cellular survival.', 'methods': 'Based on the provided text, the methods or approaches mentioned are:\\n\\n* Determining the crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide\\n* NMR chemical shift analyses of USP7 bound by EBNA1 and p53\\n* Functional studies (no specific details provided)\\n\\nLet me know if you have any further questions or need assistance with anything else!', 'models': 'Based on the provided text, the following models or frameworks are discussed or used:\\n\\n* The crystal structure of the p53 binding domain of USP7 alone and bound to an EBNA1 peptide\\n* NMR chemical shift analyses of USP7 bound by EBNA1 and p53\\n* TRAF-C domains of TNF-receptor associated factors (mentioned as a comparison)\\n\\nSo, the output is:', 'funding': 'The answer is: N/A'}}\n"
     ]
    }
   ],
   "source": [
    "for key in dico:\n",
    "    dico[key].update({\"topic\":get_topic(dico[key][\"abstract\"])})\n",
    "    dico[key].update(get_info(dico[key][\"abstract\"],affiliation=\"What affiliations do the authors or characters in the text have?\",\n",
    "                        new_materials=\"Does the text mention any new materials or discoveries?\",\n",
    "                        screening_algorithms=\"Are there any screening algorithms or systematic procedures discussed in the text?\",\n",
    "                        ai_algorithms=\"Does the text reference any AI algorithms or methods related to artificial intelligence?\",\n",
    "                        workflow=\"Can you describe the workflow or process followed in the text?\",\n",
    "                        methods=\"Can you summarize the methods or approaches mentioned in the text?\",\n",
    "                        models=\"What models or frameworks are discussed or used in the text?\",\n",
    "                        funding=\"Does the text mention any funding sources or sponsors?\"))\n",
    "\n",
    "print(dico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(dico, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"output.json\", 'w') as file:\n",
    "    json.dump(dico, file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
