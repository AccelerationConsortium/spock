{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Spock: LLM-based Tool for Bibliometric Analysis of  Scientific Literature\n",
    "\n",
    "### Tool Presentation:\n",
    "\n",
    "Researchers often need to work with peer publications within their lab, which can be both time-consuming and resource-demanding. This involves obtaining structured data, conducting thorough literature reviews, and post-processing findings to support their research objectives. \n",
    "Large Language Models (LLMs) and their capability of understanding and generating natural language text bring promising opportunities that can be integrated into a researcher's daily life to simply enhance automation and research pace.\n",
    "One such integration is the Spock, a bibliometric analysis tool integrated within Slack, designed to interact with the Acceleration Consortium members' Google scholar profile.\n",
    "The workflow follows an automatic retrieval of authors' peer-reviewed and non-peer-reviewed papers and patents from journals and preprint servers (i.e., arXiv, chemRxiv) submissions.\n",
    "This data is then post-processed via Retrieval-Augmented Generation (RAG) allowing an in-depth analysis of papers by giving, for instance, details about the scientific workflow and techniques used by the author of a scientific paper or describing AI/screening algorithms mentioned in the paper. Multi-class classification of the publication's topics in accelerated materials discovery is also an important feature of our tool. \n",
    "It can provide insights by keeping a systematic track of what researchers at the Laboratory are writing, compare research groups within the organization over several years to identify trends and opportunities, and facilitate easier interaction among scientists. Finally, it helps in preparing and submitting future research proposals.\n",
    "\n",
    "### Features of project:\n",
    "\n",
    "\n",
    "Automated Data Retrieval:\n",
    "LLM-Enhanced Analysis: Uses Large Language Models (LLMs) for Retrieval-Augmented Generation (RAG) to provide detailed analysis of scientific workflows, techniques, and AI/screening algorithms mentioned in papers.\n",
    "Multi-class Classification of papers:.\n",
    "Slack Integration.\n",
    "Research Tracking and Interaction.\n",
    "\n",
    "\n",
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import Bot_LLM,Author,Publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features walkthrough\n",
    "\n",
    "We are going to use an \"example\" using my mentor's (Mehrad Ansari's) latest paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bot_LLM(folder_path = 'db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the Author data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m author \u001b[38;5;241m=\u001b[39m Author(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMehrad Ansari\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fetching latest date\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m latest_publication \u001b[38;5;241m=\u001b[39m Publication(\u001b[43mauthor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last_publication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(latest_publication)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Setting up and ouputing in a json file\u001b[39;00m\n",
      "File \u001b[0;32m~/clone/spock/Spock_demo/utilities.py:344\u001b[0m, in \u001b[0;36mAuthor.get_last_publication\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03mGet the last publication of the author.\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    dict: A dict containing information about the last publication.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m search_query \u001b[38;5;241m=\u001b[39m scholarly\u001b[38;5;241m.\u001b[39msearch_author(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauthor_name)\n\u001b[0;32m--> 344\u001b[0m first_author_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msearch_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m author \u001b[38;5;241m=\u001b[39m scholarly\u001b[38;5;241m.\u001b[39mfill(first_author_result)\n\u001b[1;32m    346\u001b[0m first_publication \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(author[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublications\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m    347\u001b[0m                            key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpub_year\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    348\u001b[0m                            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpub_year\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbib\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m    349\u001b[0m                            reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scholarly/_navigator.py:250\u001b[0m, in \u001b[0;36mNavigator.search_authors\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_authors\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mAuthor:\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generator that returns Author objects from the author search page\"\"\"\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     soup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m     author_parser \u001b[38;5;241m=\u001b[39m AuthorParser(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scholarly/_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_soup\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BeautifulSoup:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://scholar.google.com\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     html \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    241\u001b[0m     res \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/scholarly/_navigator.py:114\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[0;34m(self, pagerequest, premium)\u001b[0m\n\u001b[1;32m    112\u001b[0m w \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(w)\n\u001b[0;32m--> 114\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpagerequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m premium \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:  \u001b[38;5;66;03m# premium methods may contain sensitive information\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession proxy config is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pm\u001b[38;5;241m.\u001b[39m_proxies))\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_client.py:1054\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, url, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1039\u001b[0m     url: URLTypes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     extensions: RequestExtensions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1048\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;124;03m    Send a `GET` request.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    826\u001b[0m )\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/ssl.py:1295\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1294\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/spock_package/lib/python3.11/ssl.py:1168\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initiating Author object\n",
    "author = Author(\"Mehrad Ansari\")\n",
    "\n",
    "# Fetching latest date\n",
    "latest_publication = Publication(author.get_last_publication())\n",
    "\n",
    "print(latest_publication)\n",
    "# Setting up and ouputing in a json file\n",
    "author.setup_author(\"output.json\", latest_publication)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning the PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 pdfs/closing_the_execution_gap_in_generative_ai_for_chemicals_and_materials_freeways_or_safeguards.pdf\n",
      "0 pdfs/closing_the_execution_gap_in_generative_ai_for_chemicals_and_materials_freeways_or_safeguards.pdf\n",
      "attempt to write a readonly database\n",
      "pdfs/closing_the_execution_gap_in_generative_ai_for_chemicals_and_materials_freeways_or_safeguards.pdf done\n",
      "1 pdfs/History-agnostic battery degradation inference.pdf\n",
      "file already done\n",
      "pdfs/History-agnostic battery degradation inference.pdf done\n",
      "2 pdfs/A_data-driven_framework_to_improve_the_wear_resistance_of_a_low-alloy_steel_fabricated_by_laser_powder_bed_fusion.pdf\n",
      "1 pdfs/A_data-driven_framework_to_improve_the_wear_resistance_of_a_low-alloy_steel_fabricated_by_laser_powder_bed_fusion.pdf\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, here is the output:\n",
      "\n",
      "```\n",
      "{\n",
      "\"Authors\": [\n",
      "    {\"Name\": \"Jiahui Zhang\", \"Affiliation\": \"University of Toronto\"},\n",
      "    {\"Name\": \"Sagar Patel\", \"Affiliation\": \"Nikon SLM Solutions\"},\n",
      "    {\"Name\": \"Zhiying Liu\", \"Affiliation\": \"University of Toronto\"},\n",
      "    {\"Name\": \"Wandong Wang\", \"Affiliation\": \"University of Toronto\"}\n",
      "]\n",
      "}\n",
      "```\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, the topics of the paper appear to be:\n",
      "\n",
      "1. Improving wear resistance of low-alloy steel fabricated by laser powder bed fusion (LPBF)\n",
      "2. Developing a data-driven framework for optimizing wear resistance\n",
      "3. Investigating the effects of parameter optimization on material properties and wear performance\n",
      "4. Comparing the results with existing literature on wear resistance in LPBF-processed materials.\n",
      "\n",
      "These topics are inferred from the title, abstract, and content of the paper, as well as the keywords and phrases used in the text.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No, the article does not mention any new material discovery. It appears to be a study on improving the wear resistance of low-alloy steel fabricated by laser powder bed fusion using parameter optimization. The authors declare that they have no competing interests or personal relationships that could influence their work. There is no indication of a new material discovery in the abstract, introduction, results, or discussion sections of the article.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know. The provided text does not mention screening algorithms or describe a systematic procedure for identifying individuals with a particular condition or trait. The paper appears to be focused on additive manufacturing and materials science, rather than healthcare or medical research. Therefore, I am unable to identify any screening algorithms used in the paper.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know the answer to this question as it is not related to the provided text. The provided text appears to be a research paper on laser powder bed fusion (LPBF) and its applications, with no mention of AI algorithms or machine learning.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Unfortunately, I don't know the answer. The provided context only includes information about the publication and its authors, but it doesn't describe the workflow used by the authors in their research.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know. The text provided appears to be the abstract and introduction of an academic paper, as well as some figures and acknowledgments. It does not contain a specific section or passage that describes the methods used in the study. If you're looking for more information on the methods used in this research, I would recommend reviewing the full article or contacting the authors directly.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know. The provided text does not mention any specific models used in the article. It seems to be a research paper discussing wear resistance and laser powder bed fusion, but it doesn't provide details on the mathematical or computational models employed.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Yes, the article mentions that the authors received funding support from several sources:\n",
      "\n",
      "* Federal Economic Development Agency for Southern Ontario (FedDev Ontario) grant #814654)\n",
      "* Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant #570708-2021\n",
      "* RGPIN-2018-05731), the CentreforAnalyticsandArtificialIntelligenceEngineering(CARTE) Seed Funding program, NewFrontiers Research Fund-Exploration(NFRFE-2019-00603), DataSciences Institute Catalyst Grant, and NSERC Alliance Grants—Missions ALLRP\n",
      "-----\n",
      "{'affiliation': 'Based on the provided context, here is the output:\\n\\n```\\n{\\n\"Authors\": [\\n    {\"Name\": \"Jiahui Zhang\", \"Affiliation\": \"University of Toronto\"},\\n    {\"Name\": \"Sagar Patel\", \"Affiliation\": \"Nikon SLM Solutions\"},\\n    {\"Name\": \"Zhiying Liu\", \"Affiliation\": \"University of Toronto\"},\\n    {\"Name\": \"Wandong Wang\", \"Affiliation\": \"University of Toronto\"}\\n]\\n}\\n```', 'topic': 'Based on the provided context, the topics of the paper appear to be:\\n\\n1. Improving wear resistance of low-alloy steel fabricated by laser powder bed fusion (LPBF)\\n2. Developing a data-driven framework for optimizing wear resistance\\n3. Investigating the effects of parameter optimization on material properties and wear performance\\n4. Comparing the results with existing literature on wear resistance in LPBF-processed materials.\\n\\nThese topics are inferred from the title, abstract, and content of the paper, as well as the keywords and phrases used in the text.', 'new materials': 'No, the article does not mention any new material discovery. It appears to be a study on improving the wear resistance of low-alloy steel fabricated by laser powder bed fusion using parameter optimization. The authors declare that they have no competing interests or personal relationships that could influence their work. There is no indication of a new material discovery in the abstract, introduction, results, or discussion sections of the article.', 'screening algorithms': \"I don't know. The provided text does not mention screening algorithms or describe a systematic procedure for identifying individuals with a particular condition or trait. The paper appears to be focused on additive manufacturing and materials science, rather than healthcare or medical research. Therefore, I am unable to identify any screening algorithms used in the paper.\", 'AI algorithms': \"I don't know the answer to this question as it is not related to the provided text. The provided text appears to be a research paper on laser powder bed fusion (LPBF) and its applications, with no mention of AI algorithms or machine learning.\", 'workflow': \"Unfortunately, I don't know the answer. The provided context only includes information about the publication and its authors, but it doesn't describe the workflow used by the authors in their research.\", 'methods': \"I don't know. The text provided appears to be the abstract and introduction of an academic paper, as well as some figures and acknowledgments. It does not contain a specific section or passage that describes the methods used in the study. If you're looking for more information on the methods used in this research, I would recommend reviewing the full article or contacting the authors directly.\", 'models': \"I don't know. The provided text does not mention any specific models used in the article. It seems to be a research paper discussing wear resistance and laser powder bed fusion, but it doesn't provide details on the mathematical or computational models employed.\", 'funding': 'Yes, the article mentions that the authors received funding support from several sources:\\n\\n* Federal Economic Development Agency for Southern Ontario (FedDev Ontario) grant #814654)\\n* Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant #570708-2021\\n* RGPIN-2018-05731), the CentreforAnalyticsandArtificialIntelligenceEngineering(CARTE) Seed Funding program, NewFrontiers Research Fund-Exploration(NFRFE-2019-00603), DataSciences Institute Catalyst Grant, and NSERC Alliance Grants—Missions ALLRP'}\n",
      "pdfs/A_data-driven_framework_to_improve_the_wear_resistance_of_a_low-alloy_steel_fabricated_by_laser_powder_bed_fusion.pdf done\n",
      "3 pdfs/Data-science-based_reconstruction_of_3-D_membrane_pore_structure_using_a_single_2-D_micrograph.pdf\n",
      "2 pdfs/Data-science-based_reconstruction_of_3-D_membrane_pore_structure_using_a_single_2-D_micrograph.pdf\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know the answer to that question because it is not provided within the given context. The text does not mention anything about the authors' affiliations or provide any information that would allow me to determine their affiliations.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The topics of this paper appear to be:\n",
      "\n",
      "1. Developing a novel approach for reconstructing 3-D structures of membranes using single 2-D micrographs.\n",
      "2. Characterizing the properties and performance of membrane structures, including porosity, permeability, tortuosity, and pore size distribution (PSD).\n",
      "3. Discussing the advantages of focused ion beam-scanning electron microscopy (FIB-SEM) in generating high-resolution 3-D images of membranes and its applications in membrane science.\n",
      "4. Exploring the challenges and limitations of using FIB-SEM for characterizing soft, poorly conducting materials like polymeric membranes.\n",
      "\n",
      "These topics seem to be centered around the development and application of a new method for analyzing membrane structures and their properties, with a focus on the use of FIB-SEM technology.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No, the article does not mention any new material discovery. It discusses a novel approach to reconstructing the 3D structure of a membrane using a single 2D cross-sectional micrograph, and presents results comparing the properties of the original and reconstructed structures. The focus is on developing a method for characterizing membrane structures, rather than discovering new materials.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There is no mention of screening algorithms being used in this paper. The text discusses feature extraction from 2D images and mentions various techniques such as distance maps, histogram of the distance map, cross-sectional area, axes ratio, equivalent radius, solidity, and mean distance map. These methods are used to analyze porous structures or membrane properties, but they are not related to screening algorithms for identifying individuals with a particular condition or trait.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm happy to help! However, I don't see a question being asked in the provided context. The text appears to be discussing FIB-SEM tomography and 3D morphological characterization of microporous layers, as well as image segmentation and thresholding techniques.\n",
      "\n",
      "If you meant to ask a question related to AI algorithms, please feel free to rephrase your question or provide more context, and I'll do my best to help!\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, I can summarize the workflow used by the author:\n",
      "\n",
      "1. Calculate a normalized histogram of the distance map for both solid and void phases.\n",
      "2. Combine these two histograms to generate a combined distance function (CDF).\n",
      "3. Generate a 3-D matrix representing the membrane with random values between 0 and 1.\n",
      "4. Apply a 3-D Gaussian filter to introduce spatial correlation, with the standard deviation affecting pore sizes.\n",
      "5. Create a second matrix with larger pores occurring towards the bottom of the membrane by using a larger standard deviation in the Gaussian filter.\n",
      "6. Combine these two matrices with relative proportions weighted by distance from the top of the structure.\n",
      "7. Apply thresholding to binarize the combined matrix and differentiate between void and solid phases.\n",
      "8. Use morphological closing to smooth sharp corners and make pores more circular.\n",
      "\n",
      "This workflow is used to generate 3-D porous structures that can be optimized for membrane development.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Yes, I can help with that! Based on the provided context, here is a methods description:\n",
      "\n",
      "The method employed to extract features from 2-D images involves the following steps:\n",
      "\n",
      "1. Image Segmentation: The algorithm starts by selecting a random slice and performing image segmentation. This step assigns a label to each pixel of the image such that pixels with the same label have similar visual characteristics.\n",
      "2. Thresholding: The easiest segmentation approach is thresholding, where any pixels whose intensity levels exceed the threshold are fixed to a foreground value, while the other pixels have a background value.\n",
      "3. Adaptive Thresholding: In this study, adaptive thresholding was used instead of conventional thresholding. This involves using an algorithm in MATLAB that dynamically changes the threshold value at different parts of the image.\n",
      "\n",
      "The feature extracted from the segmented image is the histogram of the distance map, which captures the statistical distribution of the pore and solid through a membrane. The Euclidean distance between each pixel and the nearest non-zero pixel was calculated to generate this feature.\n",
      "\n",
      "These methods allowed for the calculation of the tortuosity of the membrane using a single 2-D micrograph with high accuracy and low standard deviation.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "According to the text, two main models were used:\n",
      "\n",
      "1. **Pore Network Model**: This model is used to describe the void/solid phase as a collection of bodies and throats (Fig. 5). It was employed to quantify the membrane properties.\n",
      "2. **FlowDict module** and **FilterDict-Media solver**: These modules are part of the GeoDict software, which were used to assess the water flux through the 3-D structure and model gold nanoparticle retention under a pressure difference.\n",
      "\n",
      "Please let me know if you'd like me to clarify anything!\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know. The text does not explicitly mention funding sources or sponsors.\n",
      "-----\n",
      "{'affiliation': \"I don't know the answer to that question because it is not provided within the given context. The text does not mention anything about the authors' affiliations or provide any information that would allow me to determine their affiliations.\", 'topic': 'The topics of this paper appear to be:\\n\\n1. Developing a novel approach for reconstructing 3-D structures of membranes using single 2-D micrographs.\\n2. Characterizing the properties and performance of membrane structures, including porosity, permeability, tortuosity, and pore size distribution (PSD).\\n3. Discussing the advantages of focused ion beam-scanning electron microscopy (FIB-SEM) in generating high-resolution 3-D images of membranes and its applications in membrane science.\\n4. Exploring the challenges and limitations of using FIB-SEM for characterizing soft, poorly conducting materials like polymeric membranes.\\n\\nThese topics seem to be centered around the development and application of a new method for analyzing membrane structures and their properties, with a focus on the use of FIB-SEM technology.', 'new materials': 'No, the article does not mention any new material discovery. It discusses a novel approach to reconstructing the 3D structure of a membrane using a single 2D cross-sectional micrograph, and presents results comparing the properties of the original and reconstructed structures. The focus is on developing a method for characterizing membrane structures, rather than discovering new materials.', 'screening algorithms': 'There is no mention of screening algorithms being used in this paper. The text discusses feature extraction from 2D images and mentions various techniques such as distance maps, histogram of the distance map, cross-sectional area, axes ratio, equivalent radius, solidity, and mean distance map. These methods are used to analyze porous structures or membrane properties, but they are not related to screening algorithms for identifying individuals with a particular condition or trait.', 'AI algorithms': \"I'm happy to help! However, I don't see a question being asked in the provided context. The text appears to be discussing FIB-SEM tomography and 3D morphological characterization of microporous layers, as well as image segmentation and thresholding techniques.\\n\\nIf you meant to ask a question related to AI algorithms, please feel free to rephrase your question or provide more context, and I'll do my best to help!\", 'workflow': 'Based on the provided context, I can summarize the workflow used by the author:\\n\\n1. Calculate a normalized histogram of the distance map for both solid and void phases.\\n2. Combine these two histograms to generate a combined distance function (CDF).\\n3. Generate a 3-D matrix representing the membrane with random values between 0 and 1.\\n4. Apply a 3-D Gaussian filter to introduce spatial correlation, with the standard deviation affecting pore sizes.\\n5. Create a second matrix with larger pores occurring towards the bottom of the membrane by using a larger standard deviation in the Gaussian filter.\\n6. Combine these two matrices with relative proportions weighted by distance from the top of the structure.\\n7. Apply thresholding to binarize the combined matrix and differentiate between void and solid phases.\\n8. Use morphological closing to smooth sharp corners and make pores more circular.\\n\\nThis workflow is used to generate 3-D porous structures that can be optimized for membrane development.', 'methods': 'Yes, I can help with that! Based on the provided context, here is a methods description:\\n\\nThe method employed to extract features from 2-D images involves the following steps:\\n\\n1. Image Segmentation: The algorithm starts by selecting a random slice and performing image segmentation. This step assigns a label to each pixel of the image such that pixels with the same label have similar visual characteristics.\\n2. Thresholding: The easiest segmentation approach is thresholding, where any pixels whose intensity levels exceed the threshold are fixed to a foreground value, while the other pixels have a background value.\\n3. Adaptive Thresholding: In this study, adaptive thresholding was used instead of conventional thresholding. This involves using an algorithm in MATLAB that dynamically changes the threshold value at different parts of the image.\\n\\nThe feature extracted from the segmented image is the histogram of the distance map, which captures the statistical distribution of the pore and solid through a membrane. The Euclidean distance between each pixel and the nearest non-zero pixel was calculated to generate this feature.\\n\\nThese methods allowed for the calculation of the tortuosity of the membrane using a single 2-D micrograph with high accuracy and low standard deviation.', 'models': \"According to the text, two main models were used:\\n\\n1. **Pore Network Model**: This model is used to describe the void/solid phase as a collection of bodies and throats (Fig. 5). It was employed to quantify the membrane properties.\\n2. **FlowDict module** and **FilterDict-Media solver**: These modules are part of the GeoDict software, which were used to assess the water flux through the 3-D structure and model gold nanoparticle retention under a pressure difference.\\n\\nPlease let me know if you'd like me to clarify anything!\", 'funding': \"I don't know. The text does not explicitly mention funding sources or sponsors.\"}\n",
      "pdfs/Data-science-based_reconstruction_of_3-D_membrane_pore_structure_using_a_single_2-D_micrograph.pdf done\n",
      "4 pdfs/Assessment_of_chemistry_knowledge_in_large_language_models_that_generate_code.pdf\n",
      "3 pdfs/Assessment_of_chemistry_knowledge_in_large_language_models_that_generate_code.pdf\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, I can infer that the authors' affiliations are not explicitly stated in the text. However, I can try to identify some possible affiliations based on the research groups mentioned:\n",
      "\n",
      "* The authors mention \"our research groups\" and \"members of our research groups\", suggesting that they may be affiliated with academic institutions or organizations involved in chemistry research.\n",
      "\n",
      "Here's a dictionary output with the inferred affiliations:\n",
      "\n",
      "```\n",
      "{\n",
      "\"Authors\": [\n",
      "    {\"Affiliation\": \"Academy of Sciences\"},\n",
      "    {\"Affiliation\": \"University of Chemistry\"},\n",
      "    {\"Affiliation\": \"Research Institute for Chemistry\"}\n",
      "]\n",
      "}\n",
      "```\n",
      "\n",
      "Please note that these affiliations are not explicitly stated in the text and may not be accurate.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, the topics of the paper appear to be:\n",
      "\n",
      "1. Chemistry and chemical engineering\n",
      "2. Natural language processing (NLP) and machine learning (ML)\n",
      "3. Code generation using Large Language Models (LLMs)\n",
      "4. Expert evaluations and prompt engineering\n",
      "5. Automated code completion and natural language processing\n",
      "\n",
      "The specific subtopics covered in the paper include:\n",
      "\n",
      "* Using LLMs for code generation and completion\n",
      "* Evaluating the performance of different models on various chemistry-related tasks\n",
      "* Investigating the relationship between prompt difficulty and model accuracy\n",
      "* Discussing ways to improve model performance through prompt engineering and contextual information.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No, the article does not mention any new material discovery. The article focuses on the performance of a language model called Davinci-codex and its ability to generate code in various domains, including chemistry. It discusses the accuracy and limitations of the model, but it does not report on any new discoveries or findings related to materials science or any other field.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There is no explicit mention of a screening algorithm in the provided context. The paper discusses the use of Large Language Models (LLMs) for chemistry-related tasks and evaluates their performance on various prompts. It does not mention or describe any specific screening algorithms.\n",
      "\n",
      "However, it's possible that some of the prompts used to test the LLMs' capabilities could be interpreted as a form of screening algorithm, aiming to identify certain characteristics or properties in molecules. For instance, prompts like \"return the residual dipole couplings given a SMILES string\" or \"generate syntactically valid code to compute force constants for a two-atom harmonic oscillator with different masses\" could be seen as a simplified version of a screening algorithm.\n",
      "\n",
      "However, without explicit mention of a screening algorithm in the paper, it's difficult to provide a more specific answer.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, it appears that the authors of the paper are discussing the use of AI algorithms, specifically Large Language Models (LLMs), in solving specific tasks. They mention that davinci-codex is a model that can correctly answer prompts across a range of topics and domains.\n",
      "\n",
      "The text also mentions \"prompt engineering\" as a mechanism to improve performance, which suggests that the authors are exploring ways to optimize the input prompts to elicit more accurate responses from the AI models.\n",
      "\n",
      "Additionally, the paper discusses the use of ChatGPT to solve problems, indicating that the authors are interested in exploring the capabilities of these AI algorithms in various domains.\n",
      "\n",
      "Overall, the context suggests that the authors are focused on developing and applying AI algorithms to solve specific tasks, including those requiring human intelligence.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, it appears that the authors of the paper tested the language models InstructGPT and davinci on various chemistry-related tasks. Here's a summary of their workflow:\n",
      "\n",
      "1. **Testing molecular structures**: The authors tested the ability of InstructGPT to convert natural language descriptions of molecules into SMILES (Simplified Molecular Input Line Entry System) notation.\n",
      "2. **Evaluating accuracy**: They evaluated the accuracy of InstructGPT and davinci on 100 random molecules from PubChem, finding that neither model could accurately convert molecular structures from SMILES to natural language.\n",
      "3. **Analyzing limitations**: The authors identified limitations in the models' ability to perform chemical reasoning and noted that davinci tends to hallucinate functions that do not exist.\n",
      "4. **Exploring prompts**: They experimented with different prompts, including Chinese, German, and Spanish, and found that InstructGPT performed better on non-English prompts.\n",
      "5. **Assessing capabilities**: The authors tested the models' ability to generate molecules from natural language descriptions and found that InstructGPT could generate valid SMILES strings for most examples.\n",
      "\n",
      "Overall, the authors aimed to evaluate the capabilities of these language models in chemistry-related tasks and identify their strengths and limitations.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "What a delightful text! I'll try to extract the methods used in this study.\n",
      "\n",
      "**Methods**\n",
      "\n",
      "The study explores the performance of Large Language Models (LLMs) on code completion tasks. Here's an overview of their methods:\n",
      "\n",
      "1. **LLM models**: The authors use three LLM models: Cushman, davinci, and incoder.\n",
      "2. **Contexts**: They experiment with different contexts to see how they affect LLM performance. These contexts include:\n",
      "\t* Default context (no additional information)\n",
      "\t* \"Custom\" context (includes specific imports and comments)\n",
      "\t* \"Insert\" context (uses a special insert token for completions)\n",
      "3. **Prompt engineering**: The authors try various strategies to improve LLM performance, including:\n",
      "\t* Adding copyright notices\n",
      "\t* Using specific phrases (e.g., \"let's think step by step\")\n",
      "\t* Stating that the code has no bugs\n",
      "4. **Temperature control**: They vary the temperature of the LLM models (a hyperparameter) to see how it affects performance.\n",
      "5. **Bootstrapping**: To evaluate the models' accuracy, they use bootstrapping across individual prompts and temperatures, with 95% confidence intervals.\n",
      "6. **Benchmarks**: The authors run benchmarks on two types of errors: programming mistakes and spelling mistakes.\n",
      "\n",
      "These methods allow them to explore how different contexts, prompt engineering strategies, and temperature control affect LLM performance in code completion tasks.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the context provided, the models mentioned in the article are:\n",
      "\n",
      "1. Decision Transformers: This is a type of model that can be prompted with specific inputs to generate desired outputs.\n",
      "2. GPT-3: A large language model developed by OpenAI that can generate text and perform tasks such as molecule generation.\n",
      "3. Code Models: These are models trained on code data, which can be improved when prompted with specific inputs.\n",
      "\n",
      "Additionally, the article mentions other models such as Bert (Bidirectional Encoder Representations from Transformers) and PubChem, but these are not the primary focus of the discussion.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No, the article does not explicitly mention funding sources.\n",
      "-----\n",
      "{'affiliation': 'Based on the provided context, I can infer that the authors\\' affiliations are not explicitly stated in the text. However, I can try to identify some possible affiliations based on the research groups mentioned:\\n\\n* The authors mention \"our research groups\" and \"members of our research groups\", suggesting that they may be affiliated with academic institutions or organizations involved in chemistry research.\\n\\nHere\\'s a dictionary output with the inferred affiliations:\\n\\n```\\n{\\n\"Authors\": [\\n    {\"Affiliation\": \"Academy of Sciences\"},\\n    {\"Affiliation\": \"University of Chemistry\"},\\n    {\"Affiliation\": \"Research Institute for Chemistry\"}\\n]\\n}\\n```\\n\\nPlease note that these affiliations are not explicitly stated in the text and may not be accurate.', 'topic': 'Based on the provided context, the topics of the paper appear to be:\\n\\n1. Chemistry and chemical engineering\\n2. Natural language processing (NLP) and machine learning (ML)\\n3. Code generation using Large Language Models (LLMs)\\n4. Expert evaluations and prompt engineering\\n5. Automated code completion and natural language processing\\n\\nThe specific subtopics covered in the paper include:\\n\\n* Using LLMs for code generation and completion\\n* Evaluating the performance of different models on various chemistry-related tasks\\n* Investigating the relationship between prompt difficulty and model accuracy\\n* Discussing ways to improve model performance through prompt engineering and contextual information.', 'new materials': 'No, the article does not mention any new material discovery. The article focuses on the performance of a language model called Davinci-codex and its ability to generate code in various domains, including chemistry. It discusses the accuracy and limitations of the model, but it does not report on any new discoveries or findings related to materials science or any other field.', 'screening algorithms': 'There is no explicit mention of a screening algorithm in the provided context. The paper discusses the use of Large Language Models (LLMs) for chemistry-related tasks and evaluates their performance on various prompts. It does not mention or describe any specific screening algorithms.\\n\\nHowever, it\\'s possible that some of the prompts used to test the LLMs\\' capabilities could be interpreted as a form of screening algorithm, aiming to identify certain characteristics or properties in molecules. For instance, prompts like \"return the residual dipole couplings given a SMILES string\" or \"generate syntactically valid code to compute force constants for a two-atom harmonic oscillator with different masses\" could be seen as a simplified version of a screening algorithm.\\n\\nHowever, without explicit mention of a screening algorithm in the paper, it\\'s difficult to provide a more specific answer.', 'AI algorithms': 'Based on the provided context, it appears that the authors of the paper are discussing the use of AI algorithms, specifically Large Language Models (LLMs), in solving specific tasks. They mention that davinci-codex is a model that can correctly answer prompts across a range of topics and domains.\\n\\nThe text also mentions \"prompt engineering\" as a mechanism to improve performance, which suggests that the authors are exploring ways to optimize the input prompts to elicit more accurate responses from the AI models.\\n\\nAdditionally, the paper discusses the use of ChatGPT to solve problems, indicating that the authors are interested in exploring the capabilities of these AI algorithms in various domains.\\n\\nOverall, the context suggests that the authors are focused on developing and applying AI algorithms to solve specific tasks, including those requiring human intelligence.', 'workflow': \"Based on the provided context, it appears that the authors of the paper tested the language models InstructGPT and davinci on various chemistry-related tasks. Here's a summary of their workflow:\\n\\n1. **Testing molecular structures**: The authors tested the ability of InstructGPT to convert natural language descriptions of molecules into SMILES (Simplified Molecular Input Line Entry System) notation.\\n2. **Evaluating accuracy**: They evaluated the accuracy of InstructGPT and davinci on 100 random molecules from PubChem, finding that neither model could accurately convert molecular structures from SMILES to natural language.\\n3. **Analyzing limitations**: The authors identified limitations in the models' ability to perform chemical reasoning and noted that davinci tends to hallucinate functions that do not exist.\\n4. **Exploring prompts**: They experimented with different prompts, including Chinese, German, and Spanish, and found that InstructGPT performed better on non-English prompts.\\n5. **Assessing capabilities**: The authors tested the models' ability to generate molecules from natural language descriptions and found that InstructGPT could generate valid SMILES strings for most examples.\\n\\nOverall, the authors aimed to evaluate the capabilities of these language models in chemistry-related tasks and identify their strengths and limitations.\", 'methods': 'What a delightful text! I\\'ll try to extract the methods used in this study.\\n\\n**Methods**\\n\\nThe study explores the performance of Large Language Models (LLMs) on code completion tasks. Here\\'s an overview of their methods:\\n\\n1. **LLM models**: The authors use three LLM models: Cushman, davinci, and incoder.\\n2. **Contexts**: They experiment with different contexts to see how they affect LLM performance. These contexts include:\\n\\t* Default context (no additional information)\\n\\t* \"Custom\" context (includes specific imports and comments)\\n\\t* \"Insert\" context (uses a special insert token for completions)\\n3. **Prompt engineering**: The authors try various strategies to improve LLM performance, including:\\n\\t* Adding copyright notices\\n\\t* Using specific phrases (e.g., \"let\\'s think step by step\")\\n\\t* Stating that the code has no bugs\\n4. **Temperature control**: They vary the temperature of the LLM models (a hyperparameter) to see how it affects performance.\\n5. **Bootstrapping**: To evaluate the models\\' accuracy, they use bootstrapping across individual prompts and temperatures, with 95% confidence intervals.\\n6. **Benchmarks**: The authors run benchmarks on two types of errors: programming mistakes and spelling mistakes.\\n\\nThese methods allow them to explore how different contexts, prompt engineering strategies, and temperature control affect LLM performance in code completion tasks.', 'models': 'Based on the context provided, the models mentioned in the article are:\\n\\n1. Decision Transformers: This is a type of model that can be prompted with specific inputs to generate desired outputs.\\n2. GPT-3: A large language model developed by OpenAI that can generate text and perform tasks such as molecule generation.\\n3. Code Models: These are models trained on code data, which can be improved when prompted with specific inputs.\\n\\nAdditionally, the article mentions other models such as Bert (Bidirectional Encoder Representations from Transformers) and PubChem, but these are not the primary focus of the discussion.', 'funding': 'No, the article does not explicitly mention funding sources.'}\n",
      "pdfs/Assessment_of_chemistry_knowledge_in_large_language_models_that_generate_code.pdf done\n",
      "5 pdfs/cell_penetration_of_oxadiazole_containing_macrocycles.pdf\n",
      "4 pdfs/cell_penetration_of_oxadiazole_containing_macrocycles.pdf\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the context provided, here is the answer:\n",
      "\n",
      "The authors' affiliations are as follows:\n",
      "\n",
      "* Andrei K. Yudin: Davenport Research Laboratories, University of Toronto, Canada\n",
      "* Joshua A. Kritzer: Department of Chemistry, Tufts University, USA\n",
      "* Sungjoon Huh and Nefeli Batistatou: Shared affiliation (‡) with both institutions.\n",
      "\n",
      "Here is the output in dictionary format:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"Andrei K. Yudin\": [\"Davenport Research Laboratories\", \"University of Toronto\", \"Canada\"],\n",
      "    \"Joshua A. Kritzer\": [\"Department of Chemistry\", \"Tufts University\", \"USA\"],\n",
      "    \"Sungjoon Huh and Nefeli Batistatou\": [\"Shared affiliation (‡)\", \"Both institutions\"]\n",
      "}\n",
      "```\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, the topics of the paper appear to be:\n",
      "\n",
      "1. Cell penetration of cyclic peptides (Odz macrocycles)\n",
      "2. Comparison of cell penetration between Odz macrocycles and small molecule controls\n",
      "3. Effect of lysine and chloroalkane tag position on cell penetration\n",
      "4. Passive membrane permeability and lipophilicity of cyclic peptides\n",
      "\n",
      "These topics are related to the study of cellular uptake mechanisms and the design of bioactive molecules, which is a key area of research in chemical biology.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No, this article does not mention a new material discovery. The article is focused on studying the conformational properties and cell-penetrating ability of Odz macrocycles, which are small cyclic peptides. The authors investigate the effects of different substitutions and modifications on the structure and function of these molecules, but they do not report the discovery of any new materials.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, it appears that there is no specific mention of a screening algorithm being used in this paper. The study focuses on the cell penetration mechanism and stability of various peptides (compounds 1-7) using CAPA (Cell Penetration Assay) and PAMPA (Parallel Artificial Membrane Permeability Assay) assays, as well as conformation analysis by NMR spectroscopy.\n",
      "\n",
      "However, if we consider the methods used in the study, one could argue that the following algorithms are implicitly being used:\n",
      "\n",
      "1. Conformation analysis algorithm: This involves analyzing the three-dimensional structure of the peptides using NMR spectroscopy to understand their potential for cell penetration.\n",
      "2. Cell penetration mechanism identification algorithm: The study aims to identify the mechanisms by which peptides penetrate cells, which involves comparing the results from CAPA and PAMPA assays.\n",
      "\n",
      "While these algorithms are not explicitly stated in the paper, they can be inferred as being used implicitly in the analysis of the peptide's properties and behavior.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The provided context does not contain information related to AI algorithms or the question you've asked. The text appears to be a research paper discussing the design and synthesis of chloroalkane-tagged Odz macrocycles and their cell penetration properties using the CAPA method. If you meant to ask about something else, please clarify your question, and I'll do my best to help!\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, here is a summary of the workflow used by the authors:\n",
      "\n",
      "1. **Cell penetration assays**: The authors performed cell penetration assays (CAPA) using cyclic peptides (compounds 1 and 8) to determine their ability to cross cellular membranes.\n",
      "2. **PAMPA results**: The PAMPA (Parallel Artificial Membrane Permeability Assay) results for compound 8 were compared to those of compound A and its homodetic counterpart, which showed that the homodetic macrocycle had less passive permeability than the Odz cyclic peptide.\n",
      "3. **HPLC retention time analysis**: The authors used reverse-phase HPLC to measure the relative lipophilicity of the cyclic peptides. This was done by measuring the retention time (T) on a C18 stationary phase, which is a proxy for the compound's overall lipophilicity.\n",
      "\n",
      "The workflow appears to be focused on understanding the relationship between the chemical structure of the Odz cyclic peptides and their ability to cross cellular membranes, as well as how changes in side chains affect this property.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided text, here is a possible methods description:\n",
      "\n",
      "**Cell Penetration Assay (CAPA)**\n",
      "\n",
      "* The cell penetration of compounds was measured using a CAPA assay.\n",
      "* Cyclic peptides were incubated with cells in Opti-MEM for 30 minutes or 4 hours prior to chasing with CT-dye.\n",
      "\n",
      "**Passive Membrane Permeability Assay (PAMPA)**\n",
      "\n",
      "* The passive membrane permeability of cyclic peptides was measured using a PAMPA assay.\n",
      "* The retention time on reverse-phase HPLC was used as a measure of relative lipophilicity.\n",
      "\n",
      "**Reverse-Phase HPLC**\n",
      "\n",
      "* Reverse-phase HPLC was used to determine the retention time of compounds and their relative lipophilicity.\n",
      "* The gradient 95%/5% MeCN to 100% MeCN over 15 minutes was used for separation.\n",
      "\n",
      "Please note that this is a summary of the methods description based on the provided text, and it might not be an exact representation of the actual experimental procedures.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, the models used in the article appear to be:\n",
      "\n",
      "1. CAPA (cell-based assay): measures cell penetration in living cells.\n",
      "2. PAMPA (parallel artificial membrane permeation assay): measures passive permeability.\n",
      "\n",
      "Additionally, the article mentions the use of LC-MS (liquid chromatography-mass spectrometry) with a C18 column and a gradient of 95%/5% MeCN to 100% MeCN over 15 minutes to determine retention time values.\n",
      "-----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The article mentions that \"© 2024 The Author(s). Published by the Royal Society of Chemistry\" indicating that the publication was sponsored by the Royal Society of Chemistry. However, there is no explicit mention of specific funding sources or authors' affiliations in this particular text. If you're looking for more information on funding, I'd be happy to help you explore other sections of the article or provide additional context!\n",
      "-----\n",
      "{'affiliation': 'Based on the context provided, here is the answer:\\n\\nThe authors\\' affiliations are as follows:\\n\\n* Andrei K. Yudin: Davenport Research Laboratories, University of Toronto, Canada\\n* Joshua A. Kritzer: Department of Chemistry, Tufts University, USA\\n* Sungjoon Huh and Nefeli Batistatou: Shared affiliation (‡) with both institutions.\\n\\nHere is the output in dictionary format:\\n\\n```\\n{\\n    \"Andrei K. Yudin\": [\"Davenport Research Laboratories\", \"University of Toronto\", \"Canada\"],\\n    \"Joshua A. Kritzer\": [\"Department of Chemistry\", \"Tufts University\", \"USA\"],\\n    \"Sungjoon Huh and Nefeli Batistatou\": [\"Shared affiliation (‡)\", \"Both institutions\"]\\n}\\n```', 'topic': 'Based on the provided context, the topics of the paper appear to be:\\n\\n1. Cell penetration of cyclic peptides (Odz macrocycles)\\n2. Comparison of cell penetration between Odz macrocycles and small molecule controls\\n3. Effect of lysine and chloroalkane tag position on cell penetration\\n4. Passive membrane permeability and lipophilicity of cyclic peptides\\n\\nThese topics are related to the study of cellular uptake mechanisms and the design of bioactive molecules, which is a key area of research in chemical biology.', 'new materials': 'No, this article does not mention a new material discovery. The article is focused on studying the conformational properties and cell-penetrating ability of Odz macrocycles, which are small cyclic peptides. The authors investigate the effects of different substitutions and modifications on the structure and function of these molecules, but they do not report the discovery of any new materials.', 'screening algorithms': \"Based on the provided context, it appears that there is no specific mention of a screening algorithm being used in this paper. The study focuses on the cell penetration mechanism and stability of various peptides (compounds 1-7) using CAPA (Cell Penetration Assay) and PAMPA (Parallel Artificial Membrane Permeability Assay) assays, as well as conformation analysis by NMR spectroscopy.\\n\\nHowever, if we consider the methods used in the study, one could argue that the following algorithms are implicitly being used:\\n\\n1. Conformation analysis algorithm: This involves analyzing the three-dimensional structure of the peptides using NMR spectroscopy to understand their potential for cell penetration.\\n2. Cell penetration mechanism identification algorithm: The study aims to identify the mechanisms by which peptides penetrate cells, which involves comparing the results from CAPA and PAMPA assays.\\n\\nWhile these algorithms are not explicitly stated in the paper, they can be inferred as being used implicitly in the analysis of the peptide's properties and behavior.\", 'AI algorithms': \"The provided context does not contain information related to AI algorithms or the question you've asked. The text appears to be a research paper discussing the design and synthesis of chloroalkane-tagged Odz macrocycles and their cell penetration properties using the CAPA method. If you meant to ask about something else, please clarify your question, and I'll do my best to help!\", 'workflow': \"Based on the provided context, here is a summary of the workflow used by the authors:\\n\\n1. **Cell penetration assays**: The authors performed cell penetration assays (CAPA) using cyclic peptides (compounds 1 and 8) to determine their ability to cross cellular membranes.\\n2. **PAMPA results**: The PAMPA (Parallel Artificial Membrane Permeability Assay) results for compound 8 were compared to those of compound A and its homodetic counterpart, which showed that the homodetic macrocycle had less passive permeability than the Odz cyclic peptide.\\n3. **HPLC retention time analysis**: The authors used reverse-phase HPLC to measure the relative lipophilicity of the cyclic peptides. This was done by measuring the retention time (T) on a C18 stationary phase, which is a proxy for the compound's overall lipophilicity.\\n\\nThe workflow appears to be focused on understanding the relationship between the chemical structure of the Odz cyclic peptides and their ability to cross cellular membranes, as well as how changes in side chains affect this property.\", 'methods': 'Based on the provided text, here is a possible methods description:\\n\\n**Cell Penetration Assay (CAPA)**\\n\\n* The cell penetration of compounds was measured using a CAPA assay.\\n* Cyclic peptides were incubated with cells in Opti-MEM for 30 minutes or 4 hours prior to chasing with CT-dye.\\n\\n**Passive Membrane Permeability Assay (PAMPA)**\\n\\n* The passive membrane permeability of cyclic peptides was measured using a PAMPA assay.\\n* The retention time on reverse-phase HPLC was used as a measure of relative lipophilicity.\\n\\n**Reverse-Phase HPLC**\\n\\n* Reverse-phase HPLC was used to determine the retention time of compounds and their relative lipophilicity.\\n* The gradient 95%/5% MeCN to 100% MeCN over 15 minutes was used for separation.\\n\\nPlease note that this is a summary of the methods description based on the provided text, and it might not be an exact representation of the actual experimental procedures.', 'models': 'Based on the provided context, the models used in the article appear to be:\\n\\n1. CAPA (cell-based assay): measures cell penetration in living cells.\\n2. PAMPA (parallel artificial membrane permeation assay): measures passive permeability.\\n\\nAdditionally, the article mentions the use of LC-MS (liquid chromatography-mass spectrometry) with a C18 column and a gradient of 95%/5% MeCN to 100% MeCN over 15 minutes to determine retention time values.', 'funding': 'The article mentions that \"© 2024 The Author(s). Published by the Royal Society of Chemistry\" indicating that the publication was sponsored by the Royal Society of Chemistry. However, there is no explicit mention of specific funding sources or authors\\' affiliations in this particular text. If you\\'re looking for more information on funding, I\\'d be happy to help you explore other sections of the article or provide additional context!'}\n",
      "pdfs/cell_penetration_of_oxadiazole_containing_macrocycles.pdf done\n",
      "6 pdfs/AGENT-BASED_LEARNING_OF_MATERIALS_DATASETS_FROM_SCIENTIFIC_LITERATURE.pdf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def Running(file, index=0):\n",
    "\n",
    "    llm = Bot_LLM(folder_path='db/db'+str(index))\n",
    "    llm.chunk_indexing(file)    \n",
    "    #llm.folder_path = txt\n",
    "    dico = {}\n",
    "    ## Querying the RAG\n",
    "    dico['affiliation'] = llm.query_rag(\"What are the authors affiliation. Output a dictionary ?\")\n",
    "    print(\"-----\")\n",
    "    dico['topic']  = llm.query_rag(\"What are topics of the paper ?\")\n",
    "    \n",
    "    print(\"-----\")\n",
    "    dico['new materials'] = llm.query_rag(\"does the article mention any new material discovery ?\")\n",
    "    print(\"-----\")\n",
    "    dico['screening algorithms'] = llm.query_rag(\"A screening algorithm is a systematic procedure or method used to identify individuals who may have or be at risk for a particular condition or trait within a large population. These algorithms are designed to quickly and efficiently screen out those who are unlikely to have the condition, while identifying those who may require further diagnostic evaluation or intervention. If there are any, What are the screening algorithms used in the paper ?\")\n",
    "    print(\"-----\")\n",
    "    dico['AI algorithms'] = llm.query_rag(\"AI algorithms are computational methods and processes used to solve specific tasks by mimicking human intelligence. These algorithms enable machines to learn from data, make decisions, and perform tasks that typically require human intelligence.\")\n",
    "    print(\"-----\")\n",
    "    \n",
    "    dico['workflow'] = llm.query_rag(\"Can you describe to me the workflow used by the author ?\")\n",
    "    print(\"-----\")\n",
    "    dico['methods'] = llm.query_rag(\"can you do a methods description ?\")\n",
    "    print(\"-----\")\n",
    "    dico['models'] = llm.query_rag(\"what are the models used in the article ?\")\n",
    "    print(\"-----\")\n",
    "    dico['funding'] = llm.query_rag(\"does the article mention who funded it\")\n",
    "    print(\"-----\")\n",
    "    print(dico)\n",
    "    return dico\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "files_in_dir = glob.glob('pdfs'+ \"/*\")\n",
    "dico_response = {}\n",
    "\n",
    "\n",
    "def load_json_data(json_file_path):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data\n",
    "\n",
    "dico_response = load_json_data('benchmarking.json')\n",
    "i = 1\n",
    "true_index = 0\n",
    "for index,file in enumerate(files_in_dir):\n",
    "    print(index,file)\n",
    "    if true_index == 5:\n",
    "        break\n",
    "    try:\n",
    "        if file.split('/')[1] not in dico_response and \"History\" not in file.split('/')[1]:\n",
    "            print(true_index,file)\n",
    "            true_index += 1\n",
    "            dico_response[file.split('/')[1]] = Running(file,true_index)\n",
    "        else:\n",
    "            print(\"file already done\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        dico_response[file.split('/')[1]] = None\n",
    "    print(file+\" done\")\n",
    "        \n",
    "with open('benchmarking.json', 'w') as json_file:\n",
    "    json.dump(dico_response, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work and implementations\n",
    "\n",
    "Using the nougat tool for PDF data extraction (https://facebookresearch.github.io/nougat/)\n",
    "Using a better and larger LLM model (Llama 3.1 instead of the Llama 3 8b)\n",
    "Allow user to directly choose to “chat” with papers in the dataset\n",
    "Allow user to ask directly the LLM a question and get an answer from all the papers \n",
    "Publishing about the Spock project\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
