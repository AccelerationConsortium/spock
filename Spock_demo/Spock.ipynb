{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Spock: LLM-based Tool for Bibliometric Analysis of  Scientific Literature\n",
    "\n",
    "### Tool Presentation:\n",
    "\n",
    "Researchers often need to work with peer publications within their lab, which can be both time-consuming and resource-demanding. This involves obtaining structured data, conducting thorough literature reviews, and post-processing findings to support their research objectives. \n",
    "Large Language Models (LLMs) and their capability of understanding and generating natural language text bring promising opportunities that can be integrated into a researcher's daily life to simply enhance automation and research pace.\n",
    "One such integration is the Spock, a bibliometric analysis tool integrated within Slack, designed to interact with the Acceleration Consortium members' Google scholar profile.\n",
    "The workflow follows an automatic retrieval of authors' peer-reviewed and non-peer-reviewed papers and patents from journals and preprint servers (i.e., arXiv, chemRxiv) submissions.\n",
    "This data is then post-processed via Retrieval-Augmented Generation (RAG) allowing an in-depth analysis of papers by giving, for instance, details about the scientific workflow and techniques used by the author of a scientific paper or describing AI/screening algorithms mentioned in the paper. Multi-class classification of the publication's topics in accelerated materials discovery is also an important feature of our tool. \n",
    "It can provide insights by keeping a systematic track of what researchers at the Laboratory are writing, compare research groups within the organization over several years to identify trends and opportunities, and facilitate easier interaction among scientists. Finally, it helps in preparing and submitting future research proposals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import Bot_LLM,Author,Publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bot_LLM object:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features walkthrough\n",
    "\n",
    "We are going to use an \"example\" using my mentor's (Mehrad Ansari's) latest paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bot_LLM(folder_path = 'db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the Author data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF link found: https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/640a28a76642bf8c8f413f32/original/history-agnostic-battery-degradation-inference.pdf\n",
      "downloading pdf\n",
      "PDF successfully downloaded and saved to /home/youssef/clone/spock/Spock_demo/pdfs/History-agnostic battery degradation inference.pdf\n",
      "{'title': 'History-agnostic battery degradation inference', 'abstract': 'lithium-ion batteries (libs) have attracted widespread attention as an efficient energy storage device on electric vehicles (ev) to achieve emission-free mobility. however, the performance of libs deteriorates with time and usage, and the state of health of used batteries are difficult to quantify. having accurate estimations of a battery’s remaining life across different life stages would benefit maintenance, safety, and serve as a means of qualifying used batteries for second-life applications. since the full history of a battery may not always be available in downstream applications, in this study, we demonstrate a deep learning framework that enables dynamic degradation rate prediction, including both short-term and long-term forecasting, while requiring only the most recent battery usage information. specifically, our model takes a rolling window of current and voltage time-series inputs, and predicts the near-term and …', 'author': 'Mehrad Ansari and Steven B Torrisi and Amalie Trewartha and Shijing Sun', 'year': 2024, 'url': 'https://www.sciencedirect.com/science/article/pii/S2352152X23036782', 'citation': 'Journal of Energy Storage 81, 110279, 2024', 'pdf': 'https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/640a28a76642bf8c8f413f32/original/history-agnostic-battery-degradation-inference.pdf', 'topic': 'N/A'}\n",
      "PDF link found: https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/640a28a76642bf8c8f413f32/original/history-agnostic-battery-degradation-inference.pdf\n",
      "downloading pdf\n",
      "PDF successfully downloaded and saved to /home/youssef/clone/spock/Spock_demo/pdfs/History-agnostic battery degradation inference.pdf\n",
      "test https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/640a28a76642bf8c8f413f32/original/history-agnostic-battery-degradation-inference.pdf\n"
     ]
    }
   ],
   "source": [
    "# Initiating Author object\n",
    "author = Author(\"Mehrad Ansari\")\n",
    "\n",
    "# Fetching latest date\n",
    "latest_publication = Publication(author.get_last_publication())\n",
    "\n",
    "print(latest_publication)\n",
    "# Setting up and ouputing in a json file\n",
    "author.setup_author(\"output.json\", latest_publication)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the PDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanning the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport glob\\nfiles_in_dir = glob.glob(\\'pdfs\\'+ \"/*\")\\ndico_response = {}\\n\\n\\ndef load_json_data(json_file_path):\\n    with open(json_file_path, \\'r\\') as json_file:\\n        data = json.load(json_file)\\n    return data\\n\\ndico_response = load_json_data(\\'benchmarking.json\\')\\ni = 1\\ntrue_index = 40\\nfor index,file in enumerate(files_in_dir):\\n    print(index,file)\\n    try:\\n        if file.split(\\'/\\')[1] not in dico_response:\\n            print(true_index,file)\\n            true_index += 1\\n            dico_response[file.split(\\'/\\')[1]] = benchmarking(file,true_index)\\n        else:\\n            print(\"file already done\")\\n    except Exception as e:\\n        print(e)\\n        dico_response[file.split(\\'/\\')[1]] = None\\n    print(file+\" done\")\\n        \\nwith open(\\'benchmarking.json\\', \\'w\\') as json_file:\\n    json.dump(dico_response, json_file)\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "def benchmarking(file, index=0):\n",
    "\n",
    "    \"\"\"\n",
    "    llm = Bot_LLM(folder_path='db/db'+str(index))\n",
    "    llm.chunk_indexing(file)    \n",
    "    #llm.folder_path = txt\n",
    "    \"\"\"\n",
    "    dico = {}\n",
    "    ## Querying the RAG\n",
    "    dico['affiliation'] = llm.query_rag(\"What are the authors affiliation. Output a dictionary ?\")\n",
    "    print(\"-----\")\n",
    "    dico['topic']  = llm.get_topic_publication()\n",
    "    \n",
    "    print(\"-----\")\n",
    "    dico['new materials'] = llm.query_rag(\"does the article mention any new material discovery ?\")\n",
    "    print(\"-----\")\n",
    "    dico['screening algorithms'] = llm.query_rag(\"A screening algorithm is a systematic procedure or method used to identify individuals who may have or be at risk for a particular condition or trait within a large population. These algorithms are designed to quickly and efficiently screen out those who are unlikely to have the condition, while identifying those who may require further diagnostic evaluation or intervention. If there are any, What are the screening algorithms used in the paper ?\")\n",
    "    print(\"-----\")\n",
    "    dico['AI algorithms'] = llm.query_rag(\"AI algorithms are computational methods and processes used to solve specific tasks by mimicking human intelligence. These algorithms enable machines to learn from data, make decisions, and perform tasks that typically require human intelligence.\")\n",
    "    print(\"-----\")\n",
    "    \n",
    "    dico['workflow'] = llm.query_rag(\"Can you describe to me the workflow used by the author ?\")\n",
    "    print(\"-----\")\n",
    "    dico['methods'] = llm.query_rag(\"can you do a methods description ?\")\n",
    "    print(\"-----\")\n",
    "    dico['models'] = llm.query_rag(\"what are the models used in the article ?\")\n",
    "    print(\"-----\")\n",
    "    dico['funding'] = llm.query_rag(\"does the article mention who funded it\")\n",
    "    print(\"-----\")\n",
    "    print(dico)\n",
    "    return dico\n",
    "\n",
    "\n",
    "import glob\n",
    "files_in_dir = glob.glob('pdfs'+ \"/*\")\n",
    "dico_response = {}\n",
    "\n",
    "\n",
    "i = 1\n",
    "true_index = 40\n",
    "for index,file in enumerate(files_in_dir):\n",
    "    print(index,file)\n",
    "    try:\n",
    "        if file.split('/')[1] not in dico_response:\n",
    "            print(true_index,file)\n",
    "            true_index += 1\n",
    "            dico_response[file.split('/')[1]] = benchmarking(file,true_index)\n",
    "        else:\n",
    "            print(\"file already done\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        dico_response[file.split('/')[1]] = None\n",
    "    print(file+\" done\")\n",
    "        \n",
    "with open('benchmarking.json', 'w') as json_file:\n",
    "    json.dump(dico_response, json_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
